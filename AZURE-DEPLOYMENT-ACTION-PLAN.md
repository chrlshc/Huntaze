# Plan d'Action Tactique - D√©ploiement Azure AI Huntaze

**Date**: 1er d√©cembre 2024  
**Objectif**: D√©ployer l'architecture Azure AI avec routage intelligent  
**Status**: Pr√™t pour ex√©cution

---

## üéØ SITUATION ACTUELLE

### Infrastructure Existante
- ‚úÖ **AWS**: ECS Fargate + RDS + Redis + S3 (op√©rationnel)
- ‚úÖ **Terraform Azure**: Configur√© pour Azure OpenAI (GPT-4, GPT-3.5)
- ‚ö†Ô∏è **Mod√®les actuels**: Gemini + OpenAI direct (APIs externes)
- ‚ùå **DeepSeek/Llama/Mistral**: NON d√©ploy√©s (pas dans Terraform)

### √âcart avec le Plan Propos√©

Ton plan mentionne DeepSeek-R1, Llama 3.3 et Mistral Large, mais :
1. Ces mod√®les ne sont PAS dans ton `main.tf` actuel
2. Ton Terraform d√©ploie uniquement Azure OpenAI (GPT-4, GPT-3.5)
3. DeepSeek/Llama/Mistral n√©cessitent Azure AI Studio (diff√©rent d'Azure OpenAI)

---

## üîç ANALYSE: Deux Strat√©gies Possibles

### Option A: Azure OpenAI Uniquement (RECOMMAND√â)
**Avantages:**
- ‚úÖ Infrastructure Terraform d√©j√† pr√™te
- ‚úÖ D√©ploiement imm√©diat possible
- ‚úÖ GPT-4o suffit pour tous les cas d'usage
- ‚úÖ Moins de complexit√©
- ‚úÖ Co√ªts pr√©visibles

**Mod√®les disponibles:**
- GPT-4 Turbo (premium)
- GPT-4 (standard)
- GPT-3.5 Turbo (√©conomique)
- GPT-4 Vision (images)
- Text Embedding Ada-002 (embeddings)

### Option B: Multi-Provider avec Azure AI Studio
**Avantages:**
- ‚úÖ Acc√®s √† DeepSeek, Llama, Mistral
- ‚úÖ Optimisation co√ªts par cas d'usage
- ‚úÖ Diversification des providers

**Inconv√©nients:**
- ‚ùå Terraform √† r√©√©crire compl√®tement
- ‚ùå Marketplace subscriptions manuelles requises
- ‚ùå Complexit√© du routeur intelligent
- ‚ùå Gestion de 4+ endpoints diff√©rents
- ‚ùå Co√ªts de d√©veloppement √©lev√©s

---

## üí° RECOMMANDATION: Option A (Azure OpenAI)

Bas√© sur ton analyse des cas d'usage (`AI-MODELS-USAGE-ANALYSIS.md`), **Azure OpenAI suffit largement**.

### Mapping des Cas d'Usage

| Cas d'Usage | Mod√®le Actuel | Mod√®le Azure | Justification |
|-------------|---------------|--------------|---------------|
| **Chat rapide** | Gemini Flash | GPT-3.5 Turbo | Rapide, √©conomique |
| **Captions** | GPT-4o-mini | GPT-3.5 Turbo | Cr√©atif, optimis√© |
| **Analytics** | Gemini Pro | GPT-4 Turbo | Analyse complexe |
| **Sales** | Gemini Pro | GPT-4 Turbo | Persuasion, nuances |
| **Suggestions** | GPT-4o-mini | GPT-3.5 Turbo | Rapide, contextuel |

**Conclusion:** GPT-4 Turbo + GPT-3.5 Turbo couvrent 100% de tes besoins.

---

## üìã PLAN D'ACTION D√âTAILL√â

### Phase 1: Pr√©paration (15 min)

#### 1.1 V√©rifier les Pr√©requis
```bash
# V√©rifier Azure CLI
az --version

# V√©rifier Terraform
terraform --version

# Se connecter √† Azure
az login

# V√©rifier la souscription active
az account show

# Lister les souscriptions disponibles
az account list --output table
```

#### 1.2 V√©rifier les Quotas
```bash
# V√©rifier les quotas Azure OpenAI dans East US
az cognitiveservices account list-skus \
  --kind OpenAI \
  --location eastus

# V√©rifier les quotas actuels
az cognitiveservices account list \
  --resource-group huntaze-ai-production-rg \
  --output table
```

**‚ö†Ô∏è IMPORTANT:** Pas besoin de Marketplace subscriptions pour Azure OpenAI (contrairement √† DeepSeek/Llama).

---

### Phase 2: D√©ploiement Infrastructure (30 min)

#### 2.1 Pr√©parer Terraform
```bash
cd infra/terraform/azure-ai

# Initialiser Terraform
terraform init

# V√©rifier la configuration
terraform validate

# Voir le plan de d√©ploiement
terraform plan -out=tfplan
```

#### 2.2 D√©ployer l'Infrastructure
```bash
# D√©ployer (confirmer avec 'yes')
terraform apply tfplan

# Sauvegarder les outputs
terraform output > ../../../.azure-outputs.txt
```

**Ressources cr√©√©es:**
- ‚úÖ Resource Group: `huntaze-ai-production-rg`
- ‚úÖ Azure OpenAI Service (East US)
- ‚úÖ 5 D√©ploiements de mod√®les:
  - `gpt-4-turbo-prod` (100 TPU)
  - `gpt-4-standard-prod` (50 TPU)
  - `gpt-35-turbo-prod` (100 TPU)
  - `gpt-4-vision-prod` (30 TPU)
  - `text-embedding-ada-002-prod` (50 TPU)
- ‚úÖ Key Vault pour les secrets
- ‚úÖ Cognitive Search pour les vecteurs
- ‚úÖ Application Insights pour le monitoring

#### 2.3 R√©cup√©rer les Credentials
```bash
# Endpoint Azure OpenAI
AZURE_ENDPOINT=$(terraform output -raw openai_primary_endpoint)

# Cl√© API (stock√©e dans Key Vault)
AZURE_KEY=$(az cognitiveservices account keys list \
  --name huntaze-ai-production-openai-primary \
  --resource-group huntaze-ai-production-rg \
  --query key1 -o tsv)

echo "Endpoint: $AZURE_ENDPOINT"
echo "Key: $AZURE_KEY"
```

---

### Phase 3: Configuration du Routeur Intelligent (45 min)

#### 3.1 Cr√©er le Service Unifi√© Azure

Cr√©er `lib/ai/azure/azure-unified.service.ts`:

```typescript
import { AzureOpenAI } from 'openai';

export type ModelTier = 'premium' | 'standard' | 'economy' | 'vision';

export interface AIRequest {
  tier: ModelTier;
  systemPrompt: string;
  userMessage: string;
  jsonMode?: boolean;
  temperature?: number;
  maxTokens?: number;
}

export interface AIResponse {
  content: string;
  usage: {
    promptTokens: number;
    completionTokens: number;
    totalTokens: number;
  };
  model: string;
  cost: number;
}

export class AzureUnifiedService {
  private client: AzureOpenAI;
  private deployments: Record<ModelTier, string>;
  private pricing: Record<string, { input: number; output: number }>;

  constructor() {
    const endpoint = process.env.AZURE_OPENAI_ENDPOINT!;
    const apiKey = process.env.AZURE_OPENAI_API_KEY!;
    const apiVersion = process.env.AZURE_API_VERSION || '2024-05-01-preview';

    if (!endpoint || !apiKey) {
      throw new Error('Azure OpenAI credentials not configured');
    }

    this.client = new AzureOpenAI({
      endpoint,
      apiKey,
      apiVersion,
    });

    // Mapping des tiers vers les d√©ploiements
    this.deployments = {
      premium: 'gpt-4-turbo-prod',
      standard: 'gpt-4-standard-prod',
      economy: 'gpt-35-turbo-prod',
      vision: 'gpt-4-vision-prod',
    };

    // Pricing par 1K tokens (USD)
    this.pricing = {
      'gpt-4-turbo-prod': { input: 0.01, output: 0.03 },
      'gpt-4-standard-prod': { input: 0.03, output: 0.06 },
      'gpt-35-turbo-prod': { input: 0.0005, output: 0.0015 },
      'gpt-4-vision-prod': { input: 0.01, output: 0.03 },
    };
  }

  /**
   * Routage intelligent bas√© sur le cas d'usage
   */
  async generate(request: AIRequest): Promise<AIResponse> {
    const deployment = this.deployments[request.tier];

    try {
      const response = await this.client.chat.completions.create({
        model: deployment,
        messages: [
          { role: 'system', content: request.systemPrompt },
          { role: 'user', content: request.userMessage },
        ],
        temperature: request.temperature ?? this.getDefaultTemperature(request.tier),
        max_tokens: request.maxTokens ?? 1000,
        response_format: request.jsonMode ? { type: 'json_object' } : undefined,
      });

      const usage = response.usage!;
      const cost = this.calculateCost(deployment, usage);

      return {
        content: response.choices[0].message.content || '',
        usage: {
          promptTokens: usage.prompt_tokens,
          completionTokens: usage.completion_tokens,
          totalTokens: usage.total_tokens,
        },
        model: deployment,
        cost,
      };
    } catch (error) {
      console.error(`Azure AI Error on ${deployment}:`, error);
      throw new Error('Azure AI Service Unavailable');
    }
  }

  /**
   * Routage automatique bas√© sur le type de requ√™te
   */
  async autoRoute(
    systemPrompt: string,
    userMessage: string,
    options?: {
      requiresAnalysis?: boolean;
      requiresCreativity?: boolean;
      requiresSpeed?: boolean;
      jsonMode?: boolean;
    }
  ): Promise<AIResponse> {
    let tier: ModelTier = 'standard';

    // Logique de routage intelligent
    if (options?.requiresSpeed) {
      tier = 'economy'; // GPT-3.5 Turbo
    } else if (options?.requiresAnalysis) {
      tier = 'premium'; // GPT-4 Turbo
    } else if (options?.requiresCreativity) {
      tier = 'standard'; // GPT-4
    }

    return this.generate({
      tier,
      systemPrompt,
      userMessage,
      jsonMode: options?.jsonMode,
    });
  }

  private getDefaultTemperature(tier: ModelTier): number {
    switch (tier) {
      case 'premium':
        return 0.7; // Plus cr√©atif pour l'analyse
      case 'standard':
        return 0.6;
      case 'economy':
        return 0.5; // Plus d√©terministe pour le chat rapide
      case 'vision':
        return 0.7;
      default:
        return 0.6;
    }
  }

  private calculateCost(deployment: string, usage: any): number {
    const pricing = this.pricing[deployment];
    if (!pricing) return 0;

    const inputCost = (usage.prompt_tokens / 1000) * pricing.input;
    const outputCost = (usage.completion_tokens / 1000) * pricing.output;

    return inputCost + outputCost;
  }

  /**
   * Health check
   */
  async healthCheck(): Promise<boolean> {
    try {
      const response = await this.generate({
        tier: 'economy',
        systemPrompt: 'You are a health check bot.',
        userMessage: 'ping',
        maxTokens: 10,
      });
      return response.content.length > 0;
    } catch {
      return false;
    }
  }
}

// Singleton export
export const azureAI = new AzureUnifiedService();
```

#### 3.2 Mettre √† Jour les Variables d'Environnement

Ajouter √† `.env.production`:

```bash
# Azure OpenAI Configuration
AZURE_OPENAI_ENDPOINT=https://huntaze-ai-production-eastus.openai.azure.com/
AZURE_OPENAI_API_KEY=<votre-cl√©-depuis-terraform>
AZURE_API_VERSION=2024-05-01-preview

# D√©ploiements
AZURE_DEPLOYMENT_PREMIUM=gpt-4-turbo-prod
AZURE_DEPLOYMENT_STANDARD=gpt-4-standard-prod
AZURE_DEPLOYMENT_ECONOMY=gpt-35-turbo-prod
AZURE_DEPLOYMENT_VISION=gpt-4-vision-prod
```

---

### Phase 4: Migration des Agents (60 min)

#### 4.1 Migrer MessagingAgent

Mettre √† jour `lib/ai/agents/messaging.azure.ts`:

```typescript
import { azureAI } from '../azure/azure-unified.service';

export class MessagingAgent {
  async generateResponse(
    fanMessage: string,
    context: {
      fanName: string;
      engagementLevel: 'low' | 'medium' | 'high';
      creatorStyle: string;
    }
  ) {
    const systemPrompt = `Tu es Emma, assistante IA pour cr√©ateurs de contenu.
Style du cr√©ateur: ${context.creatorStyle}
Niveau d'engagement du fan: ${context.engagementLevel}
G√©n√®re une r√©ponse personnalis√©e, engageante et authentique.`;

    return await azureAI.autoRoute(systemPrompt, fanMessage, {
      requiresSpeed: true, // Chat rapide ‚Üí GPT-3.5 Turbo
      requiresCreativity: context.engagementLevel === 'high',
    });
  }
}
```

#### 4.2 Migrer ContentAgent

Mettre √† jour `lib/ai/agents/content.azure.ts`:

```typescript
import { azureAI } from '../azure/azure-unified.service';

export class ContentAgent {
  async generateCaption(
    platform: string,
    contentInfo: {
      type: string;
      description: string;
      mood: string;
      targetAudience: string;
    }
  ) {
    const systemPrompt = `Tu es un expert en cr√©ation de contenu pour ${platform}.
G√©n√®re une caption optimis√©e avec hashtags pertinents.
Type: ${contentInfo.type}
Mood: ${contentInfo.mood}
Audience: ${contentInfo.targetAudience}`;

    return await azureAI.autoRoute(systemPrompt, contentInfo.description, {
      requiresCreativity: true, // Cr√©ativit√© ‚Üí GPT-4
    });
  }
}
```

#### 4.3 Migrer AnalyticsAgent

Mettre √† jour `lib/ai/agents/analytics.azure.ts`:

```typescript
import { azureAI } from '../azure/azure-unified.service';

export class AnalyticsAgent {
  async analyzePerformance(metrics: any) {
    const systemPrompt = `Tu es Alex, expert en analytics.
Analyse ces m√©triques et g√©n√®re des insights actionnables.
Retourne un JSON structur√© avec insights, recommendations, patterns et predictions.`;

    return await azureAI.autoRoute(
      systemPrompt,
      JSON.stringify(metrics),
      {
        requiresAnalysis: true, // Analyse complexe ‚Üí GPT-4 Turbo
        jsonMode: true,
      }
    );
  }
}
```

#### 4.4 Migrer SalesAgent

Mettre √† jour `lib/ai/agents/sales.azure.ts`:

```typescript
import { azureAI } from '../azure/azure-unified.service';

export class SalesAgent {
  async optimizeSalesMessage(
    currentMessage: string,
    fanProfile: any,
    context: any
  ) {
    const systemPrompt = `Tu es un expert en optimisation de conversion.
Analyse ce message de vente et optimise-le pour maximiser la conversion.
Profil du fan: ${JSON.stringify(fanProfile)}
Contexte: ${JSON.stringify(context)}`;

    return await azureAI.autoRoute(systemPrompt, currentMessage, {
      requiresAnalysis: true, // Persuasion complexe ‚Üí GPT-4 Turbo
      requiresCreativity: true,
    });
  }
}
```

---

### Phase 5: Circuit Breaker & Fallback (30 min)

#### 5.1 Impl√©menter le Circuit Breaker

Cr√©er `lib/ai/azure/circuit-breaker.ts`:

```typescript
export class CircuitBreaker {
  private failures: number = 0;
  private lastFailureTime: number = 0;
  private state: 'closed' | 'open' | 'half-open' = 'closed';
  
  private readonly threshold = 5; // 5 √©checs cons√©cutifs
  private readonly timeout = 60000; // 60 secondes
  private readonly resetTimeout = 30000; // 30 secondes

  async execute<T>(fn: () => Promise<T>): Promise<T> {
    if (this.state === 'open') {
      if (Date.now() - this.lastFailureTime > this.resetTimeout) {
        this.state = 'half-open';
      } else {
        throw new Error('Circuit breaker is OPEN');
      }
    }

    try {
      const result = await fn();
      this.onSuccess();
      return result;
    } catch (error) {
      this.onFailure();
      throw error;
    }
  }

  private onSuccess() {
    this.failures = 0;
    this.state = 'closed';
  }

  private onFailure() {
    this.failures++;
    this.lastFailureTime = Date.now();

    if (this.failures >= this.threshold) {
      this.state = 'open';
      console.error('Circuit breaker opened after', this.failures, 'failures');
    }
  }

  getState() {
    return {
      state: this.state,
      failures: this.failures,
      lastFailureTime: this.lastFailureTime,
    };
  }
}
```

#### 5.2 Ajouter le Fallback vers OpenAI Direct

Mettre √† jour `azure-unified.service.ts`:

```typescript
import OpenAI from 'openai';

export class AzureUnifiedService {
  private azureClient: AzureOpenAI;
  private fallbackClient: OpenAI;
  private circuitBreaker: CircuitBreaker;

  constructor() {
    // Azure OpenAI (primaire)
    this.azureClient = new AzureOpenAI({...});
    
    // OpenAI direct (fallback)
    this.fallbackClient = new OpenAI({
      apiKey: process.env.OPENAI_API_KEY,
    });

    this.circuitBreaker = new CircuitBreaker();
  }

  async generate(request: AIRequest): Promise<AIResponse> {
    try {
      // Essayer Azure d'abord
      return await this.circuitBreaker.execute(() =>
        this.generateAzure(request)
      );
    } catch (error) {
      console.warn('Azure failed, falling back to OpenAI direct');
      return await this.generateFallback(request);
    }
  }

  private async generateFallback(request: AIRequest): Promise<AIResponse> {
    const modelMap = {
      premium: 'gpt-4-turbo-preview',
      standard: 'gpt-4',
      economy: 'gpt-3.5-turbo',
      vision: 'gpt-4-vision-preview',
    };

    const response = await this.fallbackClient.chat.completions.create({
      model: modelMap[request.tier],
      messages: [
        { role: 'system', content: request.systemPrompt },
        { role: 'user', content: request.userMessage },
      ],
      temperature: request.temperature ?? 0.7,
    });

    // ... retourner la r√©ponse format√©e
  }
}
```

---

### Phase 6: Tests & Validation (30 min)

#### 6.1 Test de Sant√©

```bash
# Cr√©er un script de test
cat > scripts/test-azure-ai.ts << 'EOF'
import { azureAI } from '../lib/ai/azure/azure-unified.service';

async function testAzureAI() {
  console.log('üß™ Testing Azure AI Service...\n');

  // Test 1: Health Check
  console.log('1. Health Check...');
  const healthy = await azureAI.healthCheck();
  console.log(healthy ? '‚úÖ Service is healthy' : '‚ùå Service is down');

  // Test 2: Economy Tier (Chat rapide)
  console.log('\n2. Testing Economy Tier (GPT-3.5 Turbo)...');
  const chatResponse = await azureAI.generate({
    tier: 'economy',
    systemPrompt: 'Tu es un assistant amical.',
    userMessage: 'Bonjour, comment vas-tu?',
  });
  console.log('Response:', chatResponse.content);
  console.log('Cost:', chatResponse.cost.toFixed(6), 'USD');

  // Test 3: Premium Tier (Analyse complexe)
  console.log('\n3. Testing Premium Tier (GPT-4 Turbo)...');
  const analysisResponse = await azureAI.generate({
    tier: 'premium',
    systemPrompt: 'Tu es un expert en analyse de donn√©es.',
    userMessage: 'Analyse ces m√©triques: likes=1000, comments=50, shares=20',
    jsonMode: true,
  });
  console.log('Response:', analysisResponse.content);
  console.log('Cost:', analysisResponse.cost.toFixed(6), 'USD');

  // Test 4: Auto-routing
  console.log('\n4. Testing Auto-routing...');
  const autoResponse = await azureAI.autoRoute(
    'Tu es un cr√©ateur de contenu.',
    'G√©n√®re une caption Instagram pour une photo de coucher de soleil',
    { requiresCreativity: true }
  );
  console.log('Response:', autoResponse.content);
  console.log('Model used:', autoResponse.model);
  console.log('Cost:', autoResponse.cost.toFixed(6), 'USD');

  console.log('\n‚úÖ All tests passed!');
}

testAzureAI().catch(console.error);
EOF

# Ex√©cuter le test
npx tsx scripts/test-azure-ai.ts
```

#### 6.2 Test de Co√ªts

```typescript
// Comparer les co√ªts Azure vs Gemini
const testPrompt = 'G√©n√®re une caption Instagram pour une photo de plage';

// Test Gemini (ancien)
const geminiCost = 0.002; // Exemple

// Test Azure Economy
const azureResponse = await azureAI.generate({
  tier: 'economy',
  systemPrompt: 'Tu es un cr√©ateur de contenu.',
  userMessage: testPrompt,
});

console.log('Gemini cost:', geminiCost, 'USD');
console.log('Azure cost:', azureResponse.cost, 'USD');
console.log('Savings:', ((geminiCost - azureResponse.cost) / geminiCost * 100).toFixed(2), '%');
```

---

### Phase 7: Monitoring & Alerting (20 min)

#### 7.1 Configurer Application Insights

```typescript
import { ApplicationInsights } from '@azure/monitor-opentelemetry';

const appInsights = new ApplicationInsights({
  connectionString: process.env.APPLICATIONINSIGHTS_CONNECTION_STRING,
});

appInsights.start();

// Logger les requ√™tes IA
export function logAIRequest(request: AIRequest, response: AIResponse) {
  appInsights.defaultClient.trackEvent({
    name: 'AI_Request',
    properties: {
      tier: request.tier,
      model: response.model,
      tokens: response.usage.totalTokens,
      cost: response.cost,
    },
  });
}
```

#### 7.2 Cr√©er des Alertes

```bash
# Alerte si co√ªt > $100/jour
az monitor metrics alert create \
  --name "AI-Cost-Alert" \
  --resource-group huntaze-ai-production-rg \
  --scopes /subscriptions/.../resourceGroups/huntaze-ai-production-rg \
  --condition "total cost > 100" \
  --description "AI costs exceeded $100/day"

# Alerte si taux d'erreur > 5%
az monitor metrics alert create \
  --name "AI-Error-Rate-Alert" \
  --resource-group huntaze-ai-production-rg \
  --condition "error rate > 5" \
  --description "AI error rate exceeded 5%"
```

---

## üìä R√âSULTATS ATTENDUS

### Co√ªts Estim√©s (par 1M tokens)

| Mod√®le | Input | Output | Total (1M tokens) |
|--------|-------|--------|-------------------|
| GPT-4 Turbo | $10 | $30 | $40 |
| GPT-4 | $30 | $60 | $90 |
| GPT-3.5 Turbo | $0.50 | $1.50 | $2 |

### √âconomies Projet√©es

Bas√© sur ton usage actuel (14 endpoints IA):
- **Avant**: ~$500/mois (Gemini + OpenAI direct)
- **Apr√®s**: ~$300/mois (Azure OpenAI optimis√©)
- **√âconomies**: ~40% ($200/mois)

### Performance

- **Latence**: < 500ms (vs 1-2s avec APIs externes)
- **Disponibilit√©**: 99.9% SLA (vs 99% APIs publiques)
- **Throughput**: 100K TPM (vs limites APIs publiques)

---

## ‚úÖ CHECKLIST DE D√âPLOIEMENT

### Avant le D√©ploiement
- [ ] Azure CLI install√© et configur√©
- [ ] Terraform install√© (>= 1.0)
- [ ] Souscription Azure active
- [ ] Quotas v√©rifi√©s (East US)
- [ ] Variables d'environnement pr√©par√©es

### D√©ploiement
- [ ] Terraform init
- [ ] Terraform plan v√©rifi√©
- [ ] Terraform apply ex√©cut√©
- [ ] Outputs sauvegard√©s
- [ ] Credentials r√©cup√©r√©s

### Configuration
- [ ] Service unifi√© cr√©√©
- [ ] Agents migr√©s
- [ ] Circuit breaker impl√©ment√©
- [ ] Fallback configur√©
- [ ] Tests ex√©cut√©s

### Monitoring
- [ ] Application Insights configur√©
- [ ] Alertes cr√©√©es
- [ ] Dashboard cr√©√©
- [ ] Logs v√©rifi√©s

---

## üö® ROLLBACK PLAN

Si probl√®me critique:

```bash
# 1. Revenir aux anciens providers
git checkout main -- lib/ai/

# 2. Restaurer les variables d'environnement
cp .env.production.backup .env.production

# 3. Red√©marrer l'application
npm run build
pm2 restart huntaze

# 4. D√©truire l'infrastructure Azure (optionnel)
cd infra/terraform/azure-ai
terraform destroy
```

---

## üìû SUPPORT

En cas de probl√®me:
1. V√©rifier les logs Application Insights
2. V√©rifier le status du circuit breaker
3. Tester le fallback OpenAI direct
4. Contacter le support Azure si n√©cessaire

---

**Pr√™t √† d√©ployer ?** Commence par la Phase 1 ! üöÄ
