# Service AI Gemini - Huntaze

## Vue d'Ensemble

Service d'intelligence artificielle utilisant Google Gemini pour g√©n√©rer du contenu, analyser les performances et assister les cr√©ateurs de contenu.

## Migration d'OpenAI vers Gemini

### Pourquoi Gemini?

- ‚úÖ **Performance:** Mod√®les puissants (Gemini 1.5 Pro)
- ‚úÖ **Co√ªt:** Plus √©conomique qu'OpenAI
- ‚úÖ **Multimodal:** Support natif texte, image, vid√©o
- ‚úÖ **Context Window:** Jusqu'√† 2M tokens (Gemini 1.5 Pro)
- ‚úÖ **Gratuit:** Quota gratuit g√©n√©reux pour d√©buter

### Mod√®les Disponibles

| Mod√®le | Description | Use Case |
|--------|-------------|----------|
| `gemini-1.5-pro` | Le plus puissant | T√¢ches complexes, analyse approfondie |
| `gemini-1.5-flash` | Rapide et √©conomique | G√©n√©ration rapide, chatbots |
| `gemini-1.0-pro` | Stable et fiable | Production, t√¢ches standard |

## Installation

### 1. Installer le Package

```bash
npm install @google/generative-ai
```

### 2. Configurer les Variables d'Environnement

Ajouter dans `.env`:

```bash
# Google Gemini API
GEMINI_API_KEY=your-api-key-here
GEMINI_MODEL=gemini-1.5-pro
```

### 3. Obtenir une Cl√© API

1. Aller sur: https://makersuite.google.com/app/apikey
2. Cr√©er une nouvelle cl√© API
3. Copier la cl√© dans `.env`

## Utilisation

### G√©n√©ration de Texte Simple

```typescript
import { generateText } from '@/lib/ai/gemini.service';

const text = await generateText(
  '√âcris une description pour une plateforme de cr√©ateurs',
  {
    temperature: 0.7,
    maxOutputTokens: 200,
  }
);

console.log(text);
```

### Chat avec Historique

```typescript
import { chat } from '@/lib/ai/gemini.service';

const messages = [
  {
    role: 'user',
    parts: 'Bonjour! Je suis un cr√©ateur de contenu.',
  },
  {
    role: 'model',
    parts: 'Bonjour! Comment puis-je vous aider?',
  },
  {
    role: 'user',
    parts: 'Donne-moi 3 id√©es de posts Instagram.',
  },
];

const response = await chat(messages, {
  temperature: 0.8,
  maxOutputTokens: 500,
});

console.log(response);
```

### Streaming

```typescript
import { generateTextStream } from '@/lib/ai/gemini.service';

for await (const chunk of generateTextStream(
  '√âcris un guide pour TikTok',
  { maxOutputTokens: 1000 }
)) {
  process.stdout.write(chunk);
}
```

### Service Complet

```typescript
import { geminiService } from '@/lib/ai/gemini.service';

// G√©n√©rer du texte
const result = await geminiService.generateText('Hello!');
console.log(result.text);

// Compter les tokens
const tokenCount = await geminiService.countTokens('Mon texte');
console.log(`Tokens: ${tokenCount}`);

// Changer de mod√®le
geminiService.setModel('gemini-1.5-flash');
```

## Exemples d'Utilisation

### 1. G√©n√©ration de Contenu pour Cr√©ateurs

```typescript
import { generateCreatorContent } from '@/lib/ai/gemini.examples';

const post = await generateCreatorContent(
  'Instagram',
  'Conseils pour augmenter l\'engagement',
  'casual'
);

console.log(post);
```

### 2. Analyse de Performance

```typescript
import { analyzeContentPerformance } from '@/lib/ai/gemini.examples';

const analysis = await analyzeContentPerformance('post Instagram', {
  views: 10000,
  likes: 500,
  comments: 50,
  shares: 20,
});

console.log(analysis);
```

### 3. G√©n√©ration d'Id√©es

```typescript
import { generateContentIdeas } from '@/lib/ai/gemini.examples';

const ideas = await generateContentIdeas('fitness', 5);
console.log(ideas);
```

### 4. Optimisation de Bio

```typescript
import { optimizeBio } from '@/lib/ai/gemini.examples';

const optimized = await optimizeBio(
  'Cr√©ateur de contenu fitness üí™',
  'Instagram',
  'Jeunes adultes 18-35 ans'
);

console.log(optimized);
```

### 5. L√©gendes pour Images

```typescript
import { generateImageCaption } from '@/lib/ai/gemini.examples';

const caption = await generateImageCaption(
  'Coucher de soleil sur la plage',
  'inspirant',
  true
);

console.log(caption);
```

## Configuration Avanc√©e

### Options de G√©n√©ration

```typescript
interface GeminiGenerateOptions {
  temperature?: number;        // 0.0 - 1.0 (d√©faut: 0.7)
  maxOutputTokens?: number;    // Max tokens (d√©faut: 2048)
  topP?: number;               // 0.0 - 1.0 (d√©faut: 0.95)
  topK?: number;               // Nombre de tokens (d√©faut: 40)
  stopSequences?: string[];    // S√©quences d'arr√™t
}
```

### Param√®tres Recommand√©s

**Contenu Cr√©atif:**
```typescript
{
  temperature: 0.8-0.9,
  maxOutputTokens: 500-1000,
  topP: 0.95,
}
```

**Analyse/Factuel:**
```typescript
{
  temperature: 0.3-0.5,
  maxOutputTokens: 300-600,
  topP: 0.9,
}
```

**Chat/Conversation:**
```typescript
{
  temperature: 0.7,
  maxOutputTokens: 400-800,
  topP: 0.95,
}
```

## Int√©gration dans l'Application

### Route API

Cr√©er `app/api/ai/generate/route.ts`:

```typescript
import { NextRequest, NextResponse } from 'next/server';
import { generateText } from '@/lib/ai/gemini.service';

export async function POST(request: NextRequest) {
  try {
    const { prompt, options } = await request.json();
    
    const text = await generateText(prompt, options);
    
    return NextResponse.json({ text });
  } catch (error) {
    return NextResponse.json(
      { error: 'Failed to generate text' },
      { status: 500 }
    );
  }
}
```

### Hook React

Cr√©er `hooks/useGemini.ts`:

```typescript
import { useState } from 'react';

export function useGemini() {
  const [loading, setLoading] = useState(false);
  const [error, setError] = useState<string | null>(null);

  const generate = async (prompt: string, options?: any) => {
    setLoading(true);
    setError(null);

    try {
      const response = await fetch('/api/ai/generate', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ prompt, options }),
      });

      if (!response.ok) {
        throw new Error('Failed to generate');
      }

      const data = await response.json();
      return data.text;
    } catch (err) {
      setError(err instanceof Error ? err.message : 'Unknown error');
      throw err;
    } finally {
      setLoading(false);
    }
  };

  return { generate, loading, error };
}
```

## Comparaison OpenAI vs Gemini

| Fonctionnalit√© | OpenAI | Gemini |
|----------------|--------|--------|
| Prix (1M tokens) | $10-30 | $0.50-7 |
| Context Window | 128K | 2M |
| Multimodal | Limit√© | Natif |
| Streaming | ‚úÖ | ‚úÖ |
| Function Calling | ‚úÖ | ‚úÖ |
| Quota Gratuit | Limit√© | G√©n√©reux |

## Limites et Quotas

### Quota Gratuit (par minute)

- **Gemini 1.5 Pro:** 2 requ√™tes/min
- **Gemini 1.5 Flash:** 15 requ√™tes/min
- **Gemini 1.0 Pro:** 15 requ√™tes/min

### Quota Payant

- Voir: https://ai.google.dev/pricing

## S√©curit√©

### Filtres de S√©curit√©

Gemini inclut des filtres automatiques pour:
- Contenu haineux
- Harc√®lement
- Contenu sexuel
- Contenu dangereux

### Bonnes Pratiques

1. ‚úÖ Ne jamais exposer la cl√© API c√¥t√© client
2. ‚úÖ Utiliser des routes API Next.js
3. ‚úÖ Valider les entr√©es utilisateur
4. ‚úÖ Impl√©menter un rate limiting
5. ‚úÖ Logger les erreurs

## D√©pannage

### Erreur: API Key Invalid

```bash
# V√©rifier que la cl√© est bien configur√©e
echo $GEMINI_API_KEY

# R√©g√©n√©rer une nouvelle cl√© si n√©cessaire
```

### Erreur: Quota Exceeded

```bash
# Attendre 1 minute ou upgrader vers un plan payant
# Impl√©menter un syst√®me de queue pour les requ√™tes
```

### Erreur: Safety Filters

```bash
# Le contenu a √©t√© bloqu√© par les filtres de s√©curit√©
# Reformuler le prompt ou ajuster les param√®tres
```

## Ressources

- **Documentation:** https://ai.google.dev/docs
- **Pricing:** https://ai.google.dev/pricing
- **API Key:** https://makersuite.google.com/app/apikey
- **Examples:** https://ai.google.dev/examples

## Support

Pour toute question:
- Consulter la documentation officielle
- V√©rifier les exemples dans `gemini.examples.ts`
- Contacter l'√©quipe de d√©veloppement

## Rate Limiting avec ElastiCache Redis

### Migration Upstash ‚Üí ElastiCache

Le syst√®me de rate limiting a √©t√© migr√© vers AWS ElastiCache Redis pour:
- ‚úÖ R√©duire les co√ªts de 45% ($80 ‚Üí $44/mois)
- ‚úÖ Am√©liorer les performances (latence 10-20x plus rapide)
- ‚úÖ Renforcer la s√©curit√© (VPC priv√©)

### Documentation

- **Guide de d√©ploiement**: `docs/ELASTICACHE_DEPLOYMENT_GUIDE.md`
- **√âtat de la migration**: `lib/ai/ELASTICACHE_MIGRATION_STATUS.md`
- **Prochaines √©tapes**: `ELASTICACHE_NEXT_STEPS.md`

### Configuration

```bash
# Variables d'environnement
ELASTICACHE_REDIS_HOST=huntaze-redis-production.asmyhp.0001.use1.cache.amazonaws.com
ELASTICACHE_REDIS_PORT=6379
```

### Test de Connectivit√©

```bash
# V√©rifier la configuration
./scripts/verify-elasticache-setup.sh

# Tester la connexion
curl https://votre-app.amplifyapp.com/api/test-redis
```

### Utilisation

```typescript
import { checkCreatorRateLimit } from '@/lib/ai/rate-limit';

// V√©rifier le rate limit
try {
  await checkCreatorRateLimit('creator-123', 'pro');
  // Requ√™te autoris√©e
} catch (error) {
  if (error instanceof RateLimitError) {
    // Rate limit d√©pass√©
    console.log(`Retry after: ${error.retryAfter}s`);
  }
}
```

---

**Version:** 2.0  
**Date:** 2025-01-21  
**Statut:** ‚úÖ Pr√™t pour Production  
**Rate Limiting:** ‚úÖ ElastiCache Redis
