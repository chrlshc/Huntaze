# Performance Optimization Guide

## Vue d'Ensemble

Ce guide d√©taille les optimisations de performance impl√©ment√©es dans l'API Huntaze, incluant les patterns de r√©silience avanc√©s, le monitoring en temps r√©el, et les strat√©gies de test de charge.

## üèóÔ∏è Architecture de R√©silience

### 1. Circuit Breaker Pattern

Le Circuit Breaker prot√®ge contre les cascading failures et am√©liore la r√©silience du syst√®me.

#### Configuration par Type de Service

```typescript
// Services AI (OpenAI, Claude)
const aiCircuitBreaker = CircuitBreakerFactory.getCircuitBreaker('openai', 'ai_service', {
  failureThreshold: 5,      // 5 √©checs cons√©cutifs
  recoveryTimeout: 60000,   // 1 minute de r√©cup√©ration
  expectedFailureRate: 10,  // 10% d'√©checs acceptables
});

// Base de donn√©es
const dbCircuitBreaker = CircuitBreakerFactory.getCircuitBreaker('postgres', 'database', {
  failureThreshold: 3,      // 3 √©checs cons√©cutifs
  recoveryTimeout: 30000,   // 30 secondes de r√©cup√©ration
  expectedFailureRate: 5,   // 5% d'√©checs acceptables
});
```

#### Utilisation avec Decorator

```typescript
class AIService {
  @withCircuitBreaker('content-generation', 'ai_service')
  async generateContent(prompt: string): Promise<string> {
    return await this.openaiClient.generate(prompt);
  }
}
```

#### √âtats du Circuit Breaker

- **CLOSED**: Fonctionnement normal
- **OPEN**: Service indisponible, requ√™tes rejet√©es
- **HALF_OPEN**: Test de r√©cup√©ration en cours

### 2. Request Coalescing

√âvite les requ√™tes duplicatas simultan√©es et optimise l'utilisation des ressources.

#### Utilisation Basique

```typescript
const coalescer = getRequestCoalescer();

// Plusieurs appels simultan√©s ‚Üí 1 seule requ√™te
const result = await coalescer.coalesce(
  'user-stats-123',
  () => fetchUserStats('123'),
  { ttl: 30000 } // Cache 30 secondes
);
```

#### Patterns Pr√©d√©finis

```typescript
// Donn√©es utilisateur (TTL: 30s)
const userData = await CoalescingPatterns.userRequest(
  userId, 
  'profile', 
  () => fetchUserProfile(userId)
);

// Recommandations AI (TTL: 30min)
const recommendations = await CoalescingPatterns.aiRecommendations(
  userId,
  'content-ideas',
  () => generateContentIdeas(userId)
);
```

### 3. Graceful Degradation

G√®re les fallbacks intelligents et maintient la fonctionnalit√© essentielle.

#### Strat√©gies de D√©gradation

```typescript
// Fail Fast: Arr√™t d√®s qu'un service critique √©choue
const dashboardConfig = DegradationConfigs.userDashboard();
const result = await gracefulDegradation.executeWithDegradation(dashboardConfig);

// Best Effort: Tente tous les services, utilise les fallbacks
const analyticsConfig = DegradationConfigs.analytics();
const analyticsResult = await gracefulDegradation.executeWithDegradation(analyticsConfig);
```

#### Configuration des Services

```typescript
const config: DegradationConfig = {
  strategy: 'best_effort',
  globalTimeout: 10000,
  services: [
    {
      name: 'user_profile',
      priority: 'critical',
      timeout: 2000,
      fallback: () => ({ name: 'User', plan: 'free' }),
    },
    {
      name: 'ai_recommendations',
      priority: 'optional',
      timeout: 8000,
      // Pas de fallback = service optionnel
    },
  ],
};
```

## üìä Monitoring et M√©triques

### 1. Service Level Indicators (SLIs)

#### Availability SLI
- **Target**: 99.9% uptime
- **Mesure**: (successful_requests / total_requests) * 100
- **Seuils**: 
  - ‚úÖ Meeting: ‚â• 99.9%
  - ‚ö†Ô∏è At Risk: 99.5% - 99.9%
  - ‚ùå Breaching: < 99.5%

#### Latency SLI
- **Target**: P95 < 500ms, P99 < 1000ms
- **Mesure**: Distribution des temps de r√©ponse
- **Seuils**:
  - ‚úÖ Meeting: P95 ‚â§ 500ms
  - ‚ö†Ô∏è At Risk: 500ms < P95 ‚â§ 750ms
  - ‚ùå Breaching: P95 > 750ms

#### Error Rate SLI
- **Target**: < 0.1% d'erreurs serveur
- **Mesure**: (5xx_responses / total_requests) * 100
- **Seuils**:
  - ‚úÖ Meeting: ‚â§ 0.1%
  - ‚ö†Ô∏è At Risk: 0.1% - 1%
  - ‚ùå Breaching: > 1%

### 2. Health Check Avanc√©

```bash
# Health check simple
curl http://localhost:3000/api/health

# Health check d√©taill√©
curl -X POST http://localhost:3000/api/health \
  -H "Content-Type: application/json" \
  -d '{"includeDetails": true, "services": ["optimization-engine", "auth-service"]}'
```

#### R√©ponse Health Check

```json
{
  "status": "healthy",
  "timestamp": "2025-10-22T21:00:00Z",
  "uptime": 3600,
  "slis": [
    {
      "name": "Availability",
      "current": 99.95,
      "target": 99.9,
      "unit": "%",
      "status": "meeting",
      "trend": "stable"
    }
  ],
  "circuitBreakers": {
    "ai_service:optimization-engine": {
      "state": "CLOSED",
      "failureCount": 0,
      "healthStatus": "healthy"
    }
  }
}
```

## üß™ Load Testing

### 1. Types de Tests

#### Smoke Test (Validation Basique)
```bash
npm run load-test:smoke
```
- 5 utilisateurs concurrents
- 30 secondes de dur√©e
- Validation des endpoints critiques

#### Load Test (Charge Normale)
```bash
npm run load-test:load
```
- 50 utilisateurs concurrents
- 5 minutes de dur√©e
- Simulation d'usage r√©el

#### Stress Test (Charge √âlev√©e)
```bash
npm run load-test:stress
```
- 200 utilisateurs concurrents
- 10 minutes de dur√©e
- Test des limites du syst√®me

#### Spike Test (Pic Soudain)
```bash
npm run load-test:spike
```
- 500 utilisateurs concurrents
- 2 minutes de dur√©e
- Mont√©e tr√®s rapide (10s)

### 2. M√©triques de Performance

#### Seuils de R√©ussite
- **Error Rate**: < 5%
- **P95 Latency**: < 2000ms
- **P99 Latency**: < 5000ms
- **Throughput**: > 10 RPS

#### Exemple de R√©sultat

```
üìä Load Test Results:
==================================================
Total Requests: 15000
Success Rate: 99.2%
Average Response Time: 450ms
P95 Response Time: 800ms
P99 Response Time: 1200ms
Requests/Second: 50.2
Concurrent Users: 50

‚úÖ Load test passed!
```

### 3. Sc√©narios de Test

#### G√©n√©ration de Contenu (40% du trafic)
```typescript
{
  name: 'content_generation',
  weight: 40,
  requests: [
    { 
      method: 'POST', 
      path: '/api/content-ideas/generate',
      body: sampleContentRequest,
      expectedStatus: 200,
      timeout: 15000
    }
  ]
}
```

#### Optimisation (30% du trafic)
```typescript
{
  name: 'optimization',
  weight: 30,
  requests: [
    { 
      method: 'POST', 
      path: '/api/optimize/pricing',
      body: samplePricingRequest,
      expectedStatus: 200,
      timeout: 10000
    }
  ]
}
```

## üîß Configuration et Tuning

### 1. Variables d'Environnement

```bash
# Circuit Breaker Configuration
CIRCUIT_BREAKER_FAILURE_THRESHOLD=5
CIRCUIT_BREAKER_RECOVERY_TIMEOUT=60000
CIRCUIT_BREAKER_MONITORING_WINDOW=300000

# Request Coalescing
REQUEST_COALESCER_TTL=5000
REQUEST_COALESCER_MAX_CACHE_SIZE=1000

# Load Testing
LOAD_TEST_API_KEY=your-test-api-key
API_BASE_URL=http://localhost:3000

# Monitoring
MONITORING_WEBHOOK_URL=https://monitoring.example.com/webhook
SLI_AVAILABILITY_TARGET=99.9
SLI_LATENCY_P95_TARGET=500
SLI_ERROR_RATE_TARGET=0.1
```

### 2. Optimisations par Environnement

#### Development
```typescript
const config = {
  circuitBreaker: {
    failureThreshold: 3,
    recoveryTimeout: 30000,
  },
  coalescing: {
    ttl: 5000,
    maxCacheSize: 100,
  },
  monitoring: {
    logLevel: 'debug',
    metricsInterval: 1000,
  },
};
```

#### Production
```typescript
const config = {
  circuitBreaker: {
    failureThreshold: 5,
    recoveryTimeout: 60000,
  },
  coalescing: {
    ttl: 30000,
    maxCacheSize: 1000,
  },
  monitoring: {
    logLevel: 'warn',
    metricsInterval: 5000,
  },
};
```

## üìà M√©triques et Alertes

### 1. M√©triques Collect√©es

#### Par Service
- Nombre de requ√™tes
- Temps de r√©ponse (P50, P95, P99)
- Taux d'erreur
- √âtat du circuit breaker
- Utilisation du cache

#### Syst√®me
- Utilisation m√©moire
- Utilisation CPU
- Connexions actives
- Uptime

### 2. Alertes Automatiques

#### Seuils Critiques
```typescript
const alertThresholds = {
  errorRate: 5,           // 5% d'erreurs
  latencyP95: 2000,       // 2 secondes P95
  circuitBreakerOpen: 1,  // Circuit ouvert
  memoryUsage: 85,        // 85% de m√©moire
  cpuUsage: 80,           // 80% de CPU
};
```

#### Canaux d'Alerte
- **Slack**: Alertes temps r√©el
- **Email**: Incidents critiques
- **PagerDuty**: Escalade automatique
- **Webhook**: Int√©gration personnalis√©e

## üöÄ D√©ploiement et CI/CD

### 1. Pipeline de Validation

```yaml
# .github/workflows/performance.yml
name: Performance Tests

on:
  pull_request:
    branches: [main]
  push:
    branches: [main]

jobs:
  performance:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
        with:
          node-version: '18'
      
      - name: Install dependencies
        run: npm ci
      
      - name: Build application
        run: npm run build
      
      - name: Start application
        run: npm run start &
        
      - name: Wait for application
        run: sleep 30
      
      - name: Health check
        run: npm run health-check
      
      - name: Smoke test
        run: npm run load-test:smoke
      
      - name: Load test
        run: npm run load-test:load
        if: github.event_name == 'push'
```

### 2. Monitoring en Production

#### Dashboards Grafana
- **Overview**: M√©triques globales et SLIs
- **Services**: D√©tail par service
- **Infrastructure**: M√©triques syst√®me
- **Errors**: Analyse des erreurs

#### Alertes Prometheus
```yaml
groups:
  - name: api.rules
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.05
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          
      - alert: HighLatency
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 0.5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High latency detected"
```

## üéØ Recommandations d'Optimisation

### 1. Priorit√©s Imm√©diates

#### Performance
- ‚úÖ Circuit breakers impl√©ment√©s
- ‚úÖ Request coalescing actif
- ‚úÖ Graceful degradation configur√©e
- ‚úÖ Load testing automatis√©

#### Monitoring
- ‚úÖ SLIs/SLOs d√©finis
- ‚úÖ Health checks avanc√©s
- ‚úÖ M√©triques temps r√©el
- ‚úÖ Alertes automatiques

### 2. Am√©liorations Futures

#### Court Terme (1-2 semaines)
- [ ] Distributed tracing (OpenTelemetry)
- [ ] Cache warming intelligent
- [ ] Rate limiting adaptatif
- [ ] Retry budgets

#### Moyen Terme (1 mois)
- [ ] Multi-r√©gion deployment
- [ ] Predictive scaling
- [ ] ML-powered anomaly detection
- [ ] Advanced caching strategies

#### Long Terme (3 mois)
- [ ] Chaos engineering
- [ ] Auto-healing systems
- [ ] Performance ML models
- [ ] Edge computing optimization

## üìö Ressources et Documentation

### 1. Guides Techniques
- [Circuit Breaker Pattern](./circuit-breaker-guide.md)
- [Request Coalescing Best Practices](./coalescing-guide.md)
- [Load Testing Strategies](./load-testing-guide.md)
- [Monitoring and Alerting](./monitoring-guide.md)

### 2. Outils Recommand√©s
- **Load Testing**: Artillery, k6, Apache Bench
- **Monitoring**: Grafana, Prometheus, DataDog
- **Tracing**: Jaeger, Zipkin, OpenTelemetry
- **Alerting**: PagerDuty, Slack, OpsGenie

### 3. M√©triques de R√©f√©rence

#### Benchmarks Industrie
- **E-commerce**: P95 < 1s, 99.9% uptime
- **SaaS**: P95 < 500ms, 99.95% uptime
- **API**: P95 < 200ms, 99.99% uptime

#### Objectifs Huntaze
- **Availability**: 99.9% (43.2 min downtime/mois)
- **Latency**: P95 < 500ms, P99 < 1000ms
- **Error Rate**: < 0.1%
- **Throughput**: > 100 RPS

L'architecture de performance est maintenant production-ready avec une r√©silience avanc√©e et un monitoring complet ! üöÄ