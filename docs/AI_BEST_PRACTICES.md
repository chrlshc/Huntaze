# Best Practices AI pour Huntaze

## üéØ Principes Fondamentaux

### 1. Toujours Router Intelligemment
‚ùå **Mauvais:**
```typescript
// Utilise toujours le m√™me mod√®le
const response = await openai.chat.completions.create({
  model: 'gpt-4o', // Co√ªteux pour tout
  messages: [...]
});
```

‚úÖ **Bon:**
```typescript
// Laisse le routeur choisir
const response = await aiService.processRequest({
  taskType: 'chatbot',
  prompt: message
});
// Utilisera gpt-4o-mini automatiquement
```

### 2. Structure pour le Cache
‚ùå **Mauvais:**
```typescript
const prompt = `
User: ${userName}
Context: ${context}
Instructions: ${longInstructions}
Query: ${query}
`;
// Contenu dynamique m√©lang√© = pas de cache
```

‚úÖ **Bon:**
```typescript
const { system, user } = buildCachedPrompt({
  systemInstructions: longInstructions, // Statique = cach√©
  userData: userName,                    // Dynamique
  userQuery: query                       // Dynamique
});
// 90% d'√©conomie sur instructions r√©p√©t√©es
```

### 3. Stream pour l'UX
‚ùå **Mauvais:**
```typescript
const response = await aiService.processRequest({
  taskType: 'chatbot',
  prompt: message
  // Pas de streaming = attente visible
});
```

‚úÖ **Bon:**
```typescript
const response = await aiService.processRequest({
  taskType: 'chatbot',
  prompt: message,
  options: { stream: true } // R√©ponse progressive
});
```

### 4. Batch pour Non-Temps-R√©el
‚ùå **Mauvais:**
```typescript
// Traiter 1000 analytics en temps r√©el
for (const item of items) {
  await aiService.processRequest({
    taskType: 'basic_analytics',
    prompt: item
  });
}
// Co√ªt: $2/1000 requ√™tes
```

‚úÖ **Bon:**
```typescript
// Utiliser Batch API
await batchAPI.submit({
  requests: items.map(item => ({
    taskType: 'basic_analytics',
    prompt: item
  })),
  completionWindow: '24h'
});
// Co√ªt: $1/1000 requ√™tes (-50%)
```

## üîí S√©curit√© et Compliance

### 1. Toujours Valider les Inputs
```typescript
function sanitizeUserInput(input: string): string {
  // Supprimer injection prompts
  return input
    .replace(/system:|assistant:|user:/gi, '')
    .slice(0, 10000); // Limite longueur
}
```

### 2. T√¢ches Critiques = GPT-4o
```typescript
// Compliance, l√©gal, finance
const result = await aiService.processRequest({
  taskType: 'compliance',
  prompt: content,
  // Utilisera TOUJOURS gpt-4o
});
```

### 3. Logs et Audit Trail
```typescript
// Logger toutes les requ√™tes critiques
await auditLog.create({
  type: 'ai_compliance_check',
  model: response.model,
  input: sanitized(content),
  output: sanitized(response.content),
  cost: response.cost,
  timestamp: new Date()
});
```

## üí∞ Optimisation des Co√ªts

### 1. Monitorer Constamment
```typescript
// Dashboard temps r√©el
const stats = aiService.getStats();
if (stats.miniPercentage < 80) {
  alert('‚ö†Ô∏è Trop de requ√™tes full model');
}
if (stats.cacheHitRate < 70) {
  alert('‚ö†Ô∏è Cache hit rate faible');
}
```

### 2. Limiter les Tokens
```typescript
// D√©finir maxTokens appropri√©
const response = await aiService.processRequest({
  taskType: 'chatbot',
  prompt: message,
  options: {
    maxTokens: 150 // Pas 1000 pour un simple "Hi"
  }
});
```

### 3. R√©utiliser les R√©ponses
```typescript
// Cache applicatif pour FAQ
const cachedResponse = await redis.get(`faq:${question}`);
if (cachedResponse) {
  return cachedResponse; // Co√ªt: $0
}

const response = await aiService.processRequest({...});
await redis.set(`faq:${question}`, response, 'EX', 3600);
```

## üöÄ Performance

### 1. Parall√©liser Quand Possible
‚ùå **Mauvais:**
```typescript
const caption = await generateCaption(post);
const hashtags = await generateHashtags(post);
const schedule = await suggestSchedule(post);
// 3 requ√™tes s√©quentielles = 3x latence
```

‚úÖ **Bon:**
```typescript
const [caption, hashtags, schedule] = await Promise.all([
  generateCaption(post),
  generateHashtags(post),
  suggestSchedule(post)
]);
// 3 requ√™tes parall√®les = 1x latence
```

### 2. Timeout Appropri√©s
```typescript
const response = await Promise.race([
  aiService.processRequest({...}),
  timeout(5000) // 5s max
]);
```

### 3. Retry avec Backoff
```typescript
async function callWithRetry(request, maxRetries = 3) {
  for (let i = 0; i < maxRetries; i++) {
    try {
      return await aiService.processRequest(request);
    } catch (error) {
      if (i === maxRetries - 1) throw error;
      await sleep(Math.pow(2, i) * 1000); // Exponential backoff
    }
  }
}
```

## üìä Monitoring et Alertes

### 1. M√©triques Cl√©s
```typescript
// Tracker ces m√©triques
const metrics = {
  requestsPerMinute: gauge(),
  miniPercentage: gauge(),
  cacheHitRate: gauge(),
  avgLatency: histogram(),
  costPerRequest: histogram(),
  errorRate: counter()
};
```

### 2. Alertes Automatiques
```typescript
// Alerter si anomalies
if (metrics.costPerRequest.avg() > 0.01) {
  slack.send('‚ö†Ô∏è Co√ªt moyen par requ√™te √©lev√©');
}

if (metrics.errorRate.rate() > 0.05) {
  pagerduty.alert('üö® Taux d\'erreur AI > 5%');
}
```

### 3. Dashboard Temps R√©el
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ AI Usage Dashboard                  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Requests/min:        1,234          ‚îÇ
‚îÇ Mini usage:          92.3%  ‚úÖ      ‚îÇ
‚îÇ Cache hit rate:      87.5%  ‚úÖ      ‚îÇ
‚îÇ Avg latency:         234ms  ‚úÖ      ‚îÇ
‚îÇ Cost/1k requests:    $2.34  ‚úÖ      ‚îÇ
‚îÇ Error rate:          0.12%  ‚úÖ      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## üß™ Testing

### 1. Test Unitaires
```typescript
describe('AI Router', () => {
  it('should use mini for chatbot', () => {
    const decision = routeAIRequest({
      taskType: 'chatbot',
      complexityScore: 3,
      isCritical: false
    });
    expect(decision.model).toBe('gpt-4o-mini');
  });

  it('should use full for compliance', () => {
    const decision = routeAIRequest({
      taskType: 'compliance',
      complexityScore: 3,
      isCritical: true
    });
    expect(decision.model).toBe('gpt-4o');
  });
});
```

### 2. Tests d'Int√©gration
```typescript
describe('AI Service', () => {
  it('should handle real requests', async () => {
    const response = await aiService.processRequest({
      taskType: 'chatbot',
      prompt: 'Hello'
    });
    expect(response.content).toBeDefined();
    expect(response.cost).toBeLessThan(0.01);
  });
});
```

### 3. Load Testing
```typescript
// Simuler charge r√©elle
const results = await loadTest({
  duration: '5m',
  rps: 100,
  scenario: async () => {
    await aiService.processRequest({
      taskType: 'chatbot',
      prompt: randomMessage()
    });
  }
});

console.log(`Avg latency: ${results.avgLatency}ms`);
console.log(`P95 latency: ${results.p95Latency}ms`);
console.log(`Error rate: ${results.errorRate}%`);
```

## ‚úÖ Checklist Pr√©-Production

- [ ] Routage intelligent activ√©
- [ ] Prompt caching configur√©
- [ ] Streaming impl√©ment√©
- [ ] Fallback automatique test√©
- [ ] Monitoring dashboard d√©ploy√©
- [ ] Alertes configur√©es
- [ ] Logs audit en place
- [ ] Tests de charge pass√©s
- [ ] Documentation √† jour
- [ ] √âquipe form√©e

## üéì Formation √âquipe

### Pour D√©veloppeurs
1. Comprendre le routage automatique
2. Utiliser `buildCachedPrompt()` correctement
3. Choisir les bons `taskType`
4. Monitorer les co√ªts

### Pour Product Managers
1. Comprendre les √©conomies (98%)
2. Prioriser les features par co√ªt
3. Analyser les m√©triques d'usage
4. Optimiser le ROI

### Pour Support
1. Identifier les requ√™tes co√ªteuses
2. Sugg√©rer alternatives moins ch√®res
3. Escalader les anomalies
4. √âduquer les utilisateurs
