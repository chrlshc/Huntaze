# Checklist - Tests /api/store/publish

Checklist compl√®te pour valider les tests de l'endpoint de publication de boutique.

## ‚úÖ Phase 1: Cr√©ation des tests (COMPLET)

### Tests principaux
- [x] Cr√©er `tests/integration/api/store-publish.test.ts`
- [x] Impl√©menter 30+ sc√©narios de test
- [x] Couvrir 10 cat√©gories de tests
- [x] Utiliser Vitest + Zod pour validation

### Cat√©gories de tests
- [x] HTTP Methods (4 tests)
- [x] Authentication (2 tests)
- [x] Gating Middleware (3 tests)
- [x] Request Body Validation (5 tests)
- [x] Response Schema Validation (3 tests)
- [x] Error Handling (2 tests)
- [x] Performance (1 test)
- [x] Concurrent Access (2 tests)
- [x] Idempotency (1 test)
- [x] Security (4 tests)

### Sch√©mas Zod
- [x] SuccessResponseSchema (200)
- [x] GatingResponseSchema (409)
- [x] ErrorResponseSchema (401/500)

### Fixtures
- [x] Cr√©er `fixtures/store-publish-samples.ts`
- [x] D√©finir utilisateurs de test
- [x] D√©finir r√©ponses attendues
- [x] D√©finir benchmarks de performance
- [x] D√©finir patterns de s√©curit√©

### Documentation
- [x] Cr√©er `store-publish-README.md`
- [x] Mettre √† jour `docs/api-tests.md`
- [x] Cr√©er `STORE_PUBLISH_TESTS_COMPLETE.md`
- [x] Cr√©er `QUICK_START_STORE_PUBLISH_TESTS.md`
- [x] Cr√©er `STORE_PUBLISH_TEST_SCENARIOS.md`
- [x] Cr√©er `TESTS_INTEGRATION_SUMMARY.md`

---

## üîÑ Phase 2: Validation locale (√Ä FAIRE)

### Pr√©requis
- [ ] Node.js install√© (v18+)
- [ ] npm install ex√©cut√©
- [ ] Base de donn√©es configur√©e
- [ ] Variables d'environnement configur√©es

### D√©marrage
- [ ] D√©marrer le serveur de dev (`npm run dev`)
- [ ] V√©rifier que le serveur r√©pond (`http://localhost:3000`)
- [ ] V√©rifier les logs du serveur

### Ex√©cution des tests
- [ ] Ex√©cuter tous les tests
  ```bash
  npm run test:integration tests/integration/api/store-publish.test.ts
  ```
- [ ] V√©rifier que tous les tests passent (30/30)
- [ ] V√©rifier le temps d'ex√©cution (< 30s)
- [ ] V√©rifier qu'il n'y a pas de tests flaky

### Tests par cat√©gorie
- [ ] Tests HTTP Methods
  ```bash
  npm run test:integration -- --grep "HTTP Methods"
  ```
- [ ] Tests Authentication
  ```bash
  npm run test:integration -- --grep "Authentication"
  ```
- [ ] Tests Gating
  ```bash
  npm run test:integration -- --grep "Gating"
  ```
- [ ] Tests Performance
  ```bash
  npm run test:integration -- --grep "Performance"
  ```
- [ ] Tests Concurrent
  ```bash
  npm run test:integration -- --grep "Concurrent"
  ```

### Couverture de code
- [ ] Ex√©cuter avec couverture
  ```bash
  npm run test:integration -- --coverage tests/integration/api/store-publish.test.ts
  ```
- [ ] V√©rifier couverture > 80%
- [ ] Identifier les branches non couvertes
- [ ] Ajouter des tests si n√©cessaire

---

## üß™ Phase 3: Tests avec donn√©es r√©elles (√Ä FAIRE)

### Utilisateurs de test
- [ ] Cr√©er utilisateur avec paiements configur√©s
- [ ] Cr√©er utilisateur sans paiements configur√©s
- [ ] G√©n√©rer tokens d'authentification valides
- [ ] Mettre √† jour les fixtures avec vrais tokens

### Base de donn√©es
- [ ] V√©rifier que la table `user_onboarding` existe
- [ ] V√©rifier que la table `onboarding_step_definitions` existe
- [ ] V√©rifier que l'√©tape 'payments' existe
- [ ] Cr√©er des donn√©es de test dans la DB

### Tests avec vrais utilisateurs
- [ ] Tester avec utilisateur sans paiements ‚Üí 409
- [ ] Tester avec utilisateur avec paiements ‚Üí 200
- [ ] Tester avec token invalide ‚Üí 401
- [ ] Tester sans token ‚Üí 401

### Validation des r√©ponses
- [ ] V√©rifier que les correlation IDs sont uniques
- [ ] V√©rifier que les messages sont en fran√ßais
- [ ] V√©rifier que les URLs de boutique sont valides
- [ ] V√©rifier que les actions de gating sont correctes

---

## üöÄ Phase 4: Tests en staging (√Ä FAIRE)

### Configuration
- [ ] D√©ployer le code en staging
- [ ] V√©rifier que l'endpoint est accessible
- [ ] Configurer TEST_BASE_URL pour staging
  ```bash
  TEST_BASE_URL=https://staging.huntaze.com
  ```

### Ex√©cution
- [ ] Ex√©cuter tous les tests contre staging
- [ ] V√©rifier que tous les tests passent
- [ ] V√©rifier les logs du serveur staging
- [ ] V√©rifier les m√©triques de performance

### Validation
- [ ] Temps de r√©ponse acceptable (< 2s)
- [ ] Pas d'erreurs 500 inattendues
- [ ] Gating middleware fonctionne
- [ ] Correlation IDs pr√©sents dans les logs

### Monitoring
- [ ] V√©rifier que les m√©triques sont collect√©es
- [ ] V√©rifier que les logs sont structur√©s
- [ ] V√©rifier que les alertes ne se d√©clenchent pas
- [ ] V√©rifier les dashboards Grafana

---

## üîß Phase 5: Int√©gration CI/CD (√Ä FAIRE)

### Configuration GitHub Actions
- [ ] Cr√©er workflow pour tests d'int√©gration
- [ ] Configurer d√©marrage du serveur
- [ ] Configurer ex√©cution des tests
- [ ] Configurer upload de la couverture

### Workflow
```yaml
name: Integration Tests - Store Publish

on:
  push:
    branches: [main, staging]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-node@v3
      - run: npm ci
      - run: npm run build
      - run: npm start &
      - run: npx wait-on http://localhost:3000
      - run: npm run test:integration tests/integration/api/store-publish.test.ts
```

### Validation
- [ ] Workflow s'ex√©cute sur push
- [ ] Workflow s'ex√©cute sur PR
- [ ] Tests passent dans CI
- [ ] Couverture upload√©e vers Codecov
- [ ] Notifications configur√©es

### Alertes
- [ ] Configurer alertes sur √©checs de tests
- [ ] Configurer alertes sur baisse de couverture
- [ ] Configurer alertes sur d√©gradation de performance
- [ ] Tester les alertes

---

## üìä Phase 6: Monitoring production (√Ä FAIRE)

### M√©triques
- [ ] Configurer m√©triques Prometheus
  - `api_store_publish_requests_total`
  - `api_store_publish_duration_seconds`
  - `api_store_publish_errors_total`
  - `api_store_publish_gating_blocks_total`

### Dashboards
- [ ] Cr√©er dashboard Grafana pour l'endpoint
- [ ] Ajouter graphiques de taux de requ√™tes
- [ ] Ajouter graphiques de latence (p50, p95, p99)
- [ ] Ajouter graphiques de taux d'erreur
- [ ] Ajouter graphiques de gating blocks

### Alertes
- [ ] Alerter si taux d'erreur > 5%
- [ ] Alerter si p95 latency > 2s
- [ ] Alerter si taux de gating > 50%
- [ ] Alerter si endpoint down

### Logs
- [ ] V√©rifier que les logs sont structur√©s
- [ ] V√©rifier que les correlation IDs sont pr√©sents
- [ ] V√©rifier que les erreurs sont logg√©es
- [ ] Configurer r√©tention des logs

---

## üéØ Phase 7: Documentation √©quipe (√Ä FAIRE)

### Formation
- [ ] Pr√©senter les tests √† l'√©quipe
- [ ] Expliquer les patterns de test
- [ ] Montrer comment ex√©cuter les tests
- [ ] Montrer comment d√©boguer les tests

### Documentation
- [ ] Partager `QUICK_START_STORE_PUBLISH_TESTS.md`
- [ ] Partager `STORE_PUBLISH_TEST_SCENARIOS.md`
- [ ] Partager `tests/integration/api/store-publish-README.md`
- [ ] Ajouter liens dans la doc d'√©quipe

### Processus
- [ ] Documenter quand ex√©cuter les tests
- [ ] Documenter comment ajouter de nouveaux tests
- [ ] Documenter comment d√©boguer les √©checs
- [ ] Documenter le processus de review

### Support
- [ ] Cr√©er canal Slack #platform-tests
- [ ] D√©signer responsable des tests
- [ ] Planifier revues r√©guli√®res
- [ ] Documenter FAQ

---

## üîÑ Phase 8: Maintenance continue (√Ä FAIRE)

### Revues r√©guli√®res
- [ ] Revoir les tests mensuellement
- [ ] Identifier les tests flaky
- [ ] Optimiser les tests lents
- [ ] Mettre √† jour les fixtures

### M√©triques de sant√©
- [ ] Suivre le taux de succ√®s des tests
- [ ] Suivre le temps d'ex√©cution
- [ ] Suivre la couverture de code
- [ ] Suivre le nombre de tests

### Am√©liorations
- [ ] Ajouter des tests de charge (k6/Artillery)
- [ ] Ajouter des tests E2E (Playwright)
- [ ] Ajouter des tests de chaos engineering
- [ ] Am√©liorer la documentation

### √âvolution
- [ ] Adapter les tests aux changements d'API
- [ ] Ajouter des tests pour nouvelles fonctionnalit√©s
- [ ] Refactorer les tests obsol√®tes
- [ ] Partager les patterns avec autres endpoints

---

## ‚úÖ Crit√®res de succ√®s

### Tests
- ‚úÖ 30+ tests cr√©√©s
- ‚è≥ Tous les tests passent localement
- ‚è≥ Tous les tests passent en staging
- ‚è≥ Tous les tests passent en CI/CD
- ‚è≥ Couverture de code > 80%
- ‚è≥ Temps d'ex√©cution < 30s
- ‚è≥ Aucun test flaky

### Documentation
- ‚úÖ README complet cr√©√©
- ‚úÖ Sc√©narios document√©s
- ‚úÖ Patterns √©tablis
- ‚è≥ √âquipe form√©e
- ‚è≥ FAQ cr√©√©e

### Int√©gration
- ‚è≥ CI/CD configur√©
- ‚è≥ Monitoring configur√©
- ‚è≥ Alertes configur√©es
- ‚è≥ Dashboards cr√©√©s

### Processus
- ‚è≥ Processus de review √©tabli
- ‚è≥ Responsable d√©sign√©
- ‚è≥ Maintenance planifi√©e
- ‚è≥ Support disponible

---

## üìà M√©triques cibles

| M√©trique | Cible | Actuel | Status |
|----------|-------|--------|--------|
| Tests cr√©√©s | 30+ | 30+ | ‚úÖ |
| Tests passant | 100% | - | ‚è≥ |
| Couverture | > 80% | - | ‚è≥ |
| Temps d'ex√©cution | < 30s | - | ‚è≥ |
| Tests flaky | 0% | - | ‚è≥ |
| Documentation | Compl√®te | ‚úÖ | ‚úÖ |

---

## üéØ Prochaines actions

### Imm√©diat (Aujourd'hui)
1. [ ] Ex√©cuter les tests localement
2. [ ] Cr√©er des utilisateurs de test
3. [ ] Valider que tous les tests passent

### Court terme (Cette semaine)
1. [ ] Tester en staging
2. [ ] Configurer CI/CD
3. [ ] Former l'√©quipe

### Moyen terme (Ce mois)
1. [ ] D√©ployer en production
2. [ ] Configurer monitoring
3. [ ] √âtablir processus de maintenance

### Long terme (Trimestre)
1. [ ] Ajouter tests de charge
2. [ ] Ajouter tests E2E
3. [ ] √âtendre aux autres endpoints

---

**Status**: Phase 1 compl√®te ‚úÖ, Phases 2-8 √† faire ‚è≥  
**Derni√®re mise √† jour**: 2024-11-11  
**Responsable**: √âquipe Platform  
**Prochaine √©tape**: Ex√©cution locale des tests üöÄ
