# üöÄ Migration Azure AI vers East US

**Date**: 23 d√©cembre 2025  
**Objectif**: Migrer les 7 mod√®les Azure AI de France Central vers East US  
**Raison**: Latence optimale avec Vercel (20-50ms vs 100-150ms)

---

## üìä Situation Actuelle

### Mod√®les D√©ploy√©s (France Central)
```
1. DeepSeek-V3       ‚Üí francecentral.models.ai.azure.com
2. DeepSeek-R1       ‚Üí francecentral.models.ai.azure.com
3. Phi-4 Multimodal  ‚Üí francecentral.models.ai.azure.com
4. Phi-4 Mini        ‚Üí francecentral.models.ai.azure.com
5. Llama 3.3-70B     ‚Üí francecentral.models.ai.azure.com
6. Mistral Large     ‚Üí francecentral.models.ai.azure.com
7. Azure Speech      ‚Üí francecentral.api.cognitive.microsoft.com
```

### Latence Actuelle
- **France Central ‚Üí Vercel (US)**: 100-150ms
- **East US ‚Üí Vercel (US)**: 20-50ms
- **Gain**: 70-100ms par requ√™te (60-70% plus rapide)

---

## ‚öñÔ∏è D√©cision: Migrer ou Garder?

### Option 1: GARDER France Central ‚úÖ RECOMMAND√â

**Avantages**:
- ‚úÖ D√©j√† d√©ploy√© et fonctionnel
- ‚úÖ Z√©ro co√ªt de migration
- ‚úÖ Z√©ro risque de downtime
- ‚úÖ 100-150ms reste acceptable pour l'UX
- ‚úÖ Pas de reconfiguration n√©cessaire

**Inconv√©nients**:
- ‚ö†Ô∏è Latence 70-100ms plus √©lev√©e
- ‚ö†Ô∏è Pas optimal pour temps r√©el

**Verdict**: **GARDE France Central** si:
- Tu veux d√©ployer MAINTENANT sans risque
- 100-150ms de latence est acceptable
- Tu veux √©viter les co√ªts de migration

---

### Option 2: MIGRER vers East US üöÄ

**Avantages**:
- ‚úÖ Latence optimale (20-50ms)
- ‚úÖ Meilleure UX temps r√©el
- ‚úÖ Colocation avec Vercel
- ‚úÖ Meilleure performance globale

**Inconv√©nients**:
- ‚ö†Ô∏è Temps de migration: 2-4 heures
- ‚ö†Ô∏è Risque de downtime pendant migration
- ‚ö†Ô∏è Co√ªt de red√©ploiement (temps)
- ‚ö†Ô∏è Reconfiguration des endpoints

**Verdict**: **MIGRE vers East US** si:
- La latence est critique pour ton UX
- Tu as le temps pour la migration
- Tu veux la meilleure performance possible

---

## üéØ MA RECOMMANDATION

### Phase 1: D√âPLOIE MAINTENANT avec France Central

**Pourquoi?**
1. Tu as d√©j√† tout configur√©
2. 100-150ms est acceptable pour 90% des cas
3. Tu peux d√©ployer en production AUJOURD'HUI
4. Z√©ro risque

**Action**:
```bash
# Utilise les endpoints France Central actuels
AZURE_DEEPSEEK_V3_ENDPOINT=https://huntaze-ai-deepseek-v3.francecentral.models.ai.azure.com
AZURE_DEEPSEEK_R1_ENDPOINT=https://huntaze-ai-deepseek-r1.francecentral.models.ai.azure.com
# ... etc
```

### Phase 2: MIGRE vers East US plus tard (optionnel)

**Quand?**
- Apr√®s avoir valid√© que tout fonctionne
- Quand tu as 2-4 heures de disponibilit√©
- Pendant une p√©riode de faible trafic

**Comment?**
- Suis le guide de migration ci-dessous
- Teste en parall√®le avant de switcher
- Rollback facile si probl√®me

---

## üìã Guide de Migration vers East US

### √âtape 1: V√©rifier la Disponibilit√© des Mod√®les

Tous les mod√®les ne sont pas disponibles dans toutes les r√©gions.

```bash
# V√©rifier la disponibilit√© dans East US
az ml model list --region eastus --query "[?contains(name, 'deepseek')]"
az ml model list --region eastus --query "[?contains(name, 'phi-4')]"
az ml model list --region eastus --query "[?contains(name, 'llama')]"
az ml model list --region eastus --query "[?contains(name, 'mistral')]"
```

### √âtape 2: Cr√©er les Nouveaux D√©ploiements (East US)

```bash
# Script de migration
cat > deployment-beta-50users/scripts/migrate-azure-ai-eastus.sh << 'EOF'
#!/bin/bash
set -e

echo "üöÄ Migration Azure AI vers East US"
echo "=================================="

REGION="eastus"
RESOURCE_GROUP="huntaze-ai"

# 1. DeepSeek-V3
echo "üì¶ D√©ploiement DeepSeek-V3..."
az ml online-deployment create \
  --name huntaze-ai-deepseek-v3-eastus \
  --model deepseek-v3 \
  --region $REGION \
  --resource-group $RESOURCE_GROUP \
  --instance-type Standard_NC24s_v3 \
  --instance-count 1

# 2. DeepSeek-R1
echo "üì¶ D√©ploiement DeepSeek-R1..."
az ml online-deployment create \
  --name huntaze-ai-deepseek-r1-eastus \
  --model deepseek-r1 \
  --region $REGION \
  --resource-group $RESOURCE_GROUP \
  --instance-type Standard_NC24s_v3 \
  --instance-count 1

# 3. Phi-4 Multimodal
echo "üì¶ D√©ploiement Phi-4 Multimodal..."
az ml online-deployment create \
  --name huntaze-ai-phi4-multimodal-eastus \
  --model phi-4-multimodal \
  --region $REGION \
  --resource-group $RESOURCE_GROUP \
  --instance-type Standard_NC6s_v3 \
  --instance-count 1

# 4. Phi-4 Mini
echo "üì¶ D√©ploiement Phi-4 Mini..."
az ml online-deployment create \
  --name huntaze-ai-phi4-mini-eastus \
  --model phi-4-mini \
  --region $REGION \
  --resource-group $RESOURCE_GROUP \
  --instance-type Standard_NC6s_v3 \
  --instance-count 1

# 5. Llama 3.3-70B
echo "üì¶ D√©ploiement Llama 3.3-70B..."
az ml online-deployment create \
  --name huntaze-ai-llama-eastus \
  --model llama-3-3-70b \
  --region $REGION \
  --resource-group $RESOURCE_GROUP \
  --instance-type Standard_NC24s_v3 \
  --instance-count 1

# 6. Mistral Large
echo "üì¶ D√©ploiement Mistral Large..."
az ml online-deployment create \
  --name huntaze-ai-mistral-eastus \
  --model mistral-large \
  --region $REGION \
  --resource-group $RESOURCE_GROUP \
  --instance-type Standard_NC24s_v3 \
  --instance-count 1

# 7. Azure Speech (East US)
echo "üì¶ Cr√©ation Azure Speech Service..."
az cognitiveservices account create \
  --name huntaze-speech-eastus \
  --resource-group $RESOURCE_GROUP \
  --kind SpeechServices \
  --sku S0 \
  --location $REGION \
  --yes

echo ""
echo "‚úÖ Migration termin√©e!"
echo ""
echo "üìã Nouveaux Endpoints:"
echo "AZURE_DEEPSEEK_V3_ENDPOINT=https://huntaze-ai-deepseek-v3-eastus.eastus.models.ai.azure.com"
echo "AZURE_DEEPSEEK_R1_ENDPOINT=https://huntaze-ai-deepseek-r1-eastus.eastus.models.ai.azure.com"
echo "AZURE_PHI4_MULTIMODAL_ENDPOINT=https://huntaze-ai-phi4-multimodal-eastus.eastus.models.ai.azure.com"
echo "AZURE_PHI4_MINI_ENDPOINT=https://huntaze-ai-phi4-mini-eastus.eastus.models.ai.azure.com"
echo "AZURE_LLAMA_ENDPOINT=https://huntaze-ai-llama-eastus.eastus.models.ai.azure.com"
echo "AZURE_MISTRAL_ENDPOINT=https://huntaze-ai-mistral-eastus.eastus.models.ai.azure.com"
echo "AZURE_SPEECH_ENDPOINT=https://eastus.api.cognitive.microsoft.com"
echo "AZURE_SPEECH_REGION=eastus"

EOF

chmod +x deployment-beta-50users/scripts/migrate-azure-ai-eastus.sh
```

### √âtape 3: Tester les Nouveaux Endpoints

```bash
# Test DeepSeek-V3 (East US)
curl -X POST "https://huntaze-ai-deepseek-v3-eastus.eastus.models.ai.azure.com/v1/chat/completions" \
  -H "Content-Type: application/json" \
  -H "api-key: $AZURE_AI_API_KEY" \
  -d '{
    "messages": [{"role": "user", "content": "Hello"}],
    "max_tokens": 10
  }'

# Test Azure Speech (East US)
curl -X POST "https://eastus.api.cognitive.microsoft.com/sts/v1.0/issuetoken" \
  -H "Ocp-Apim-Subscription-Key: $AZURE_SPEECH_KEY"
```

### √âtape 4: Mettre √† Jour Vercel

```bash
# Mettre √† jour les variables d'environnement Vercel
vercel env rm AZURE_DEEPSEEK_V3_ENDPOINT production
vercel env add AZURE_DEEPSEEK_V3_ENDPOINT production
# Entrer: https://huntaze-ai-deepseek-v3-eastus.eastus.models.ai.azure.com

vercel env rm AZURE_DEEPSEEK_R1_ENDPOINT production
vercel env add AZURE_DEEPSEEK_R1_ENDPOINT production
# Entrer: https://huntaze-ai-deepseek-r1-eastus.eastus.models.ai.azure.com

# ... r√©p√©ter pour tous les endpoints

vercel env rm AZURE_SPEECH_ENDPOINT production
vercel env add AZURE_SPEECH_ENDPOINT production
# Entrer: https://eastus.api.cognitive.microsoft.com

vercel env rm AZURE_SPEECH_REGION production
vercel env add AZURE_SPEECH_REGION production
# Entrer: eastus

# Red√©ployer
vercel --prod
```

### √âtape 5: Supprimer les Anciens D√©ploiements (France Central)

**‚ö†Ô∏è ATTENTION**: Fais √ßa SEULEMENT apr√®s avoir valid√© que East US fonctionne!

```bash
# Supprimer les d√©ploiements France Central
az ml online-deployment delete --name huntaze-ai-deepseek-v3 --yes
az ml online-deployment delete --name huntaze-ai-deepseek-r1 --yes
az ml online-deployment delete --name huntaze-ai-phi4-multimodal --yes
az ml online-deployment delete --name huntaze-ai-phi4-mini --yes
az ml online-deployment delete --name huntaze-ai-llama --yes
az ml online-deployment delete --name huntaze-ai-mistral --yes
az cognitiveservices account delete --name huntaze-speech-francecentral --yes
```

---

## üìù Nouveaux Endpoints (East US)

### Variables d'Environnement Vercel (East US)

```bash
# Azure AI - East US
AZURE_DEEPSEEK_V3_ENDPOINT=https://huntaze-ai-deepseek-v3-eastus.eastus.models.ai.azure.com
AZURE_DEEPSEEK_R1_ENDPOINT=https://huntaze-ai-deepseek-r1-eastus.eastus.models.ai.azure.com
AZURE_PHI4_MULTIMODAL_ENDPOINT=https://huntaze-ai-phi4-multimodal-eastus.eastus.models.ai.azure.com
AZURE_PHI4_MINI_ENDPOINT=https://huntaze-ai-phi4-mini-eastus.eastus.models.ai.azure.com
AZURE_LLAMA_ENDPOINT=https://huntaze-ai-llama-eastus.eastus.models.ai.azure.com
AZURE_MISTRAL_ENDPOINT=https://huntaze-ai-mistral-eastus.eastus.models.ai.azure.com
AZURE_SPEECH_ENDPOINT=https://eastus.api.cognitive.microsoft.com
AZURE_SPEECH_REGION=eastus
AZURE_AI_API_KEY=<TA_CLE_AZURE_AI>
AZURE_SPEECH_KEY=<TA_CLE_AZURE_SPEECH>
```

---

## üß™ Test de Latence

### Comparer France Central vs East US

```bash
# Test latence France Central
time curl -X POST "https://huntaze-ai-deepseek-v3.francecentral.models.ai.azure.com/v1/chat/completions" \
  -H "api-key: $AZURE_AI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"messages":[{"role":"user","content":"Hello"}],"max_tokens":10}'

# Test latence East US
time curl -X POST "https://huntaze-ai-deepseek-v3-eastus.eastus.models.ai.azure.com/v1/chat/completions" \
  -H "api-key: $AZURE_AI_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{"messages":[{"role":"user","content":"Hello"}],"max_tokens":10}'
```

### R√©sultats Attendus

```
France Central: 100-150ms
East US:        20-50ms
Gain:           70-100ms (60-70% plus rapide)
```

---

## üí∞ Co√ªts de Migration

### Co√ªts Directs
- **Temps de migration**: 2-4 heures
- **Co√ªt Azure**: $0 (m√™me pricing dans toutes les r√©gions)
- **Downtime potentiel**: 0-30 minutes

### Co√ªts Indirects
- **Temps d√©veloppeur**: 2-4 heures
- **Risque de bugs**: Faible (changement d'endpoints seulement)
- **Tests requis**: 1-2 heures

### ROI
- **Gain de latence**: 70-100ms par requ√™te
- **Am√©lioration UX**: Significative pour temps r√©el
- **Co√ªt total**: ~4-6 heures de travail

---

## üö® Plan de Rollback

Si la migration √©choue, rollback facile:

```bash
# 1. Remettre les anciens endpoints dans Vercel
vercel env add AZURE_DEEPSEEK_V3_ENDPOINT production
# Entrer: https://huntaze-ai-deepseek-v3.francecentral.models.ai.azure.com

# 2. Red√©ployer
vercel --prod

# 3. Supprimer les d√©ploiements East US (optionnel)
az ml online-deployment delete --name huntaze-ai-deepseek-v3-eastus --yes
```

---

## ‚úÖ Checklist de Migration

### Avant Migration
- [ ] Backup des endpoints actuels (France Central)
- [ ] V√©rifier disponibilit√© des mod√®les dans East US
- [ ] Planifier fen√™tre de maintenance (2-4h)
- [ ] Pr√©venir les utilisateurs (si en production)

### Pendant Migration
- [ ] Cr√©er les nouveaux d√©ploiements (East US)
- [ ] Tester chaque endpoint individuellement
- [ ] Mesurer la latence (avant/apr√®s)
- [ ] Mettre √† jour Vercel env vars
- [ ] Red√©ployer l'application

### Apr√®s Migration
- [ ] Tester toutes les fonctionnalit√©s AI
- [ ] Monitorer les erreurs (24h)
- [ ] Comparer les m√©triques de performance
- [ ] Supprimer les anciens d√©ploiements (France Central)
- [ ] Documenter les nouveaux endpoints

---

## üéØ D√©cision Finale

### Option A: GARDE France Central (RECOMMAND√â pour maintenant)

**Action imm√©diate**:
```bash
# Utilise les endpoints actuels dans Vercel
# Copie-colle depuis deployment-beta-50users/COPY-PASTE-VERCEL.txt
# D√©ploie MAINTENANT
```

**Avantages**:
- ‚úÖ D√©ploiement imm√©diat
- ‚úÖ Z√©ro risque
- ‚úÖ Latence acceptable (100-150ms)

---

### Option B: MIGRE vers East US (pour performance optimale)

**Action imm√©diate**:
```bash
# 1. Ex√©cute le script de migration
./deployment-beta-50users/scripts/migrate-azure-ai-eastus.sh

# 2. Teste les nouveaux endpoints
# 3. Mets √† jour Vercel
# 4. D√©ploie
```

**Avantages**:
- ‚úÖ Latence optimale (20-50ms)
- ‚úÖ Meilleure UX
- ‚úÖ Colocation avec Vercel

---

## ü§î Ma Recommandation Personnelle

**GARDE France Central pour l'instant**, voici pourquoi:

1. **Tu peux d√©ployer MAINTENANT** sans attendre 2-4h de migration
2. **100-150ms est acceptable** pour 90% des cas d'usage
3. **Z√©ro risque** de downtime ou bugs
4. **Tu peux migrer plus tard** quand tu auras valid√© que tout fonctionne

**Migre vers East US plus tard** si:
- Tu constates que la latence impacte l'UX
- Tu as du temps pour une migration propre
- Tu veux optimiser au maximum

---

**Pr√™t √† d√©cider? Dis-moi ce que tu choisis! üöÄ**
