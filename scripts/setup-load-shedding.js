#!/usr/bin/env node

/**
 * Load Shedding Setup Script
 * Automated setup and configuration of load shedding and overload management
 */

const fs = require('fs').promises;
const path = require('path');

const LOAD_SHEDDING_CONFIG = {
  admissionControl: {
    enabled: true,
    triggers: {
      cpu: {
        warning: 70,
        shedBestEffort: 80,
        shedImportant: 90,
        emergency: 95
      },
      memory: {
        warning: 75,
        shedBestEffort: 85,
        shedImportant: 92,
        emergency: 97
      },
      latency: {
        p95Warning: 500,
        p95Shed: 1000,
        p99Shed: 2000,
        p99Emergency: 5000
      },
      queue: {
        maxDepth: 1000,
        warningDepth: 500
      }
    },
    priorityBudgets: {
      CRITICAL: 1000,
      IMPORTANT: 500,
      BEST_EFFORT: 100
    }
  },
  clientThrottling: {
    api: {
      enabled: true,
      baseDelay: 1000,
      maxDelay: 30000,
      backoffMultiplier: 2,
      jitter: true,
      windowSize: 5,
      throttleThreshold: 20,
      recoveryFactor: 0.8
    },
    database: {
      enabled: true,
      baseDelay: 500,
      maxDelay: 10000,
      backoffMultiplier: 2,
      jitter: true,
      windowSize: 5,
      throttleThreshold: 10,
      recoveryFactor: 0.8
    },
    cache: {
      enabled: true,
      baseDelay: 100,
      maxDelay: 5000,
      backoffMultiplier: 2,
      jitter: true,
      windowSize: 5,
      throttleThreshold: 30,
      recoveryFactor: 0.8
    }
  },
  middleware: {
    enabled: true,
    excludePaths: [
      '/api/health',
      '/api/monitoring',
      '/api/load-shedding',
      '/_next',
      '/favicon.ico',
      '/robots.txt'
    ],
    includePaths: [],
    defaultPriority: 'BEST_EFFORT',
    customHeaders: true,
    metricsCollection: true
  },
  loadTesting: {
    scenarios: {
      normal: {
        rps: 100,
        duration: 300,
        description: 'Normal load baseline'
      },
      double: {
        rps: 200,
        duration: 300,
        description: '2x normal load test'
      },
      triple: {
        rps: 300,
        duration: 300,
        description: '3x normal load test'
      },
      spike: {
        rps: 500,
        duration: 60,
        description: '5x spike load test'
      }
    }
  },
  monitoring: {
    metricsRetention: 86400000, // 24 hours
    alertThresholds: {
      shedLevel: 2,
      rejectionRate: 50,
      throttlingActive: 3,
      resourceUtilization: 90
    }
  }
};

async function setupLoadShedding() {
  console.log('ðŸš€ Setting up Load Shedding & Overload Management...\n');

  try {
    // 1. Create load shedding configuration file
    console.log('ðŸ“ Creating load shedding configuration...');
    await fs.writeFile(
      'load-shedding.config.json',
      JSON.stringify(LOAD_SHEDDING_CONFIG, null, 2)
    );
    console.log('âœ… Load shedding configuration created\n');

    // 2. Verify load shedding modules exist
    console.log('ðŸ” Verifying load shedding modules...');
    const modules = [
      'lib/load-shedding/admissionController.ts',
      'lib/load-shedding/clientThrottling.ts',
      'lib/load-shedding/middleware.ts'
    ];

    for (const module of modules) {
      try {
        await fs.access(module);
        console.log(`âœ… ${module}`);
      } catch (error) {
        console.log(`âŒ ${module} - Missing!`);
        throw new Error(`Required module ${module} not found`);
      }
    }
    console.log('');

    // 3. Create load shedding initialization script
    console.log('ðŸš€ Creating load shedding initialization script...');
    const initScript = `/**
 * Load Shedding System Initialization
 * Auto-generated by setup-load-shedding.js
 */

import { admissionController } from '@/lib/load-shedding/admissionController';
import { apiThrottling, databaseThrottling, cacheThrottling } from '@/lib/load-shedding/clientThrottling';
import { loadSheddingMiddleware } from '@/lib/load-shedding/middleware';

let loadSheddingInitialized = false;

export async function initializeLoadShedding() {
  if (loadSheddingInitialized) {
    console.log('Load shedding already initialized');
    return;
  }

  try {
    console.log('ðŸš€ Initializing load shedding system...');

    // Load configuration
    const config = await loadConfiguration();
    
    // Update admission controller config
    if (config.admissionControl) {
      admissionController.updateConfig(config.admissionControl);
      console.log('âœ… Admission controller configured');
    }

    // Update client throttling configs
    if (config.clientThrottling) {
      if (config.clientThrottling.api) {
        apiThrottling.updateConfig(config.clientThrottling.api);
      }
      if (config.clientThrottling.database) {
        databaseThrottling.updateConfig(config.clientThrottling.database);
      }
      if (config.clientThrottling.cache) {
        cacheThrottling.updateConfig(config.clientThrottling.cache);
      }
      console.log('âœ… Client throttling configured');
    }

    // Update middleware config
    if (config.middleware) {
      loadSheddingMiddleware.updateConfig(config.middleware);
      console.log('âœ… Load shedding middleware configured');
    }

    loadSheddingInitialized = true;
    console.log('ðŸŽ¯ Load shedding system initialized successfully');

    // Start monitoring
    startLoadSheddingMonitoring();
  } catch (error) {
    console.error('âŒ Load shedding initialization failed:', error);
    throw error;
  }
}

async function loadConfiguration() {
  try {
    const fs = await import('fs/promises');
    const configData = await fs.readFile('load-shedding.config.json', 'utf8');
    return JSON.parse(configData);
  } catch (error) {
    console.warn('Could not load load-shedding.config.json, using defaults');
    return {};
  }
}

function startLoadSheddingMonitoring() {
  // Monitor system resources every 30 seconds
  setInterval(async () => {
    try {
      const status = admissionController.getStatus();
      
      // Log warnings for high resource usage
      if (status.shedLevel >= 2) {
        console.warn(\`âš ï¸  Load shedding active (level \${status.shedLevel})\`);
      }
      
      // Log throttling status
      const throttlingMetrics = {
        api: apiThrottling.getMetrics(),
        database: databaseThrottling.getMetrics(),
        cache: cacheThrottling.getMetrics()
      };
      
      const activeThrottling = Object.entries(throttlingMetrics)
        .filter(([_, metrics]) => metrics.isThrottling)
        .map(([service, _]) => service);
      
      if (activeThrottling.length > 0) {
        console.warn(\`ðŸ”„ Client throttling active: \${activeThrottling.join(', ')}\`);
      }
    } catch (error) {
      console.error('Load shedding monitoring error:', error);
    }
  }, 30000);
}

// Auto-initialize in production
if (process.env.NODE_ENV === 'production') {
  initializeLoadShedding().catch(console.error);
}

// Export for manual initialization
export { admissionController, apiThrottling, databaseThrottling, cacheThrottling, loadSheddingMiddleware };
`;

    await fs.writeFile('lib/load-shedding/init.ts', initScript);
    console.log('âœ… Load shedding initialization script created\n');

    // 4. Create load testing scripts
    console.log('ðŸ§ª Creating load testing scripts...');
    const loadTestScript = `#!/usr/bin/env node

/**
 * Load Testing Script for Load Shedding Validation
 */

const http = require('http');
const { performance } = require('perf_hooks');

class LoadTester {
  constructor() {
    this.results = {
      requests: [],
      summary: {
        total: 0,
        successful: 0,
        failed: 0,
        rejected: 0,
        throttled: 0,
        averageLatency: 0,
        p95Latency: 0,
        p99Latency: 0
      }
    };
  }

  async runLoadTest(scenario) {
    console.log(\`ðŸ§ª Running load test: \${scenario.description}\`);
    console.log(\`   RPS: \${scenario.rps}, Duration: \${scenario.duration}s\`);
    
    const startTime = Date.now();
    const endTime = startTime + (scenario.duration * 1000);
    const requestInterval = 1000 / scenario.rps; // ms between requests
    
    const promises = [];
    let requestCount = 0;
    
    while (Date.now() < endTime) {
      const requestPromise = this.makeRequest(requestCount++);
      promises.push(requestPromise);
      
      // Wait for next request interval
      await this.sleep(requestInterval);
    }
    
    // Wait for all requests to complete
    console.log(\`â³ Waiting for \${promises.length} requests to complete...\`);
    await Promise.allSettled(promises);
    
    // Calculate results
    this.calculateSummary();
    this.printResults();
    
    return this.results;
  }
  
  async makeRequest(requestId) {
    const startTime = performance.now();
    
    try {
      const result = await this.httpRequest({
        hostname: 'localhost',
        port: 3000,
        path: '/api/health',
        method: 'GET'
      });
      
      const duration = performance.now() - startTime;
      
      this.results.requests.push({
        id: requestId,
        status: result.status,
        duration,
        timestamp: Date.now(),
        success: result.status >= 200 && result.status < 300,
        rejected: result.status === 503,
        throttled: result.status === 429
      });
    } catch (error) {
      const duration = performance.now() - startTime;
      
      this.results.requests.push({
        id: requestId,
        status: 0,
        duration,
        timestamp: Date.now(),
        success: false,
        rejected: false,
        throttled: false,
        error: error.message
      });
    }
  }
  
  httpRequest(options) {
    return new Promise((resolve, reject) => {
      const req = http.request(options, (res) => {
        let data = '';
        res.on('data', (chunk) => data += chunk);
        res.on('end', () => {
          resolve({
            status: res.statusCode,
            headers: res.headers,
            data
          });
        });
      });
      
      req.on('error', reject);
      req.setTimeout(30000, () => {
        req.destroy();
        reject(new Error('Request timeout'));
      });
      
      req.end();
    });
  }
  
  calculateSummary() {
    const requests = this.results.requests;
    const successful = requests.filter(r => r.success);
    const failed = requests.filter(r => !r.success && !r.rejected && !r.throttled);
    const rejected = requests.filter(r => r.rejected);
    const throttled = requests.filter(r => r.throttled);
    
    const latencies = requests.map(r => r.duration).sort((a, b) => a - b);
    const p95Index = Math.floor(latencies.length * 0.95);
    const p99Index = Math.floor(latencies.length * 0.99);
    
    this.results.summary = {
      total: requests.length,
      successful: successful.length,
      failed: failed.length,
      rejected: rejected.length,
      throttled: throttled.length,
      averageLatency: latencies.reduce((sum, lat) => sum + lat, 0) / latencies.length,
      p95Latency: latencies[p95Index] || 0,
      p99Latency: latencies[p99Index] || 0
    };
  }
  
  printResults() {
    const { summary } = this.results;
    
    console.log('\\nðŸ“Š Load Test Results:');
    console.log('=' .repeat(40));
    console.log(\`Total Requests: \${summary.total}\`);
    console.log(\`Successful: \${summary.successful} (\${(summary.successful / summary.total * 100).toFixed(1)}%)\`);
    console.log(\`Failed: \${summary.failed} (\${(summary.failed / summary.total * 100).toFixed(1)}%)\`);
    console.log(\`Rejected (503): \${summary.rejected} (\${(summary.rejected / summary.total * 100).toFixed(1)}%)\`);
    console.log(\`Throttled (429): \${summary.throttled} (\${(summary.throttled / summary.total * 100).toFixed(1)}%)\`);
    console.log(\`Average Latency: \${summary.averageLatency.toFixed(2)}ms\`);
    console.log(\`P95 Latency: \${summary.p95Latency.toFixed(2)}ms\`);
    console.log(\`P99 Latency: \${summary.p99Latency.toFixed(2)}ms\`);
    console.log('=' .repeat(40));
  }
  
  sleep(ms) {
    return new Promise(resolve => setTimeout(resolve, ms));
  }
}

// CLI interface
const [,, scenario] = process.argv;

const scenarios = {
  normal: { rps: 10, duration: 60, description: 'Normal load (10 RPS)' },
  double: { rps: 20, duration: 60, description: '2x load (20 RPS)' },
  triple: { rps: 30, duration: 60, description: '3x load (30 RPS)' },
  spike: { rps: 50, duration: 30, description: 'Spike load (50 RPS)' }
};

if (!scenario || !scenarios[scenario]) {
  console.log('Load Testing Script');
  console.log('');
  console.log('Usage: node scripts/load-test.js <scenario>');
  console.log('');
  console.log('Available scenarios:');
  Object.entries(scenarios).forEach(([name, config]) => {
    console.log(\`  \${name}: \${config.description}\`);
  });
  process.exit(1);
}

const tester = new LoadTester();
tester.runLoadTest(scenarios[scenario]).catch(console.error);
`;

    await fs.writeFile('scripts/load-test.js', loadTestScript);
    await fs.chmod('scripts/load-test.js', 0o755);
    console.log('âœ… Load testing script created\n');

    // 5. Create package.json scripts
    console.log('ðŸ“¦ Adding NPM scripts...');
    try {
      const packageJsonPath = 'package.json';
      const packageJson = JSON.parse(await fs.readFile(packageJsonPath, 'utf8'));
      
      packageJson.scripts = packageJson.scripts || {};
      packageJson.scripts['load-shedding:setup'] = 'node scripts/setup-load-shedding.js';
      packageJson.scripts['load-test:normal'] = 'node scripts/load-test.js normal';
      packageJson.scripts['load-test:2x'] = 'node scripts/load-test.js double';
      packageJson.scripts['load-test:3x'] = 'node scripts/load-test.js triple';
      packageJson.scripts['load-test:spike'] = 'node scripts/load-test.js spike';
      packageJson.scripts['load-shedding:status'] = 'curl http://localhost:3000/api/load-shedding/status';
      packageJson.scripts['load-shedding:dashboard'] = 'open http://localhost:3000/load-shedding/dashboard';
      
      await fs.writeFile(packageJsonPath, JSON.stringify(packageJson, null, 2));
      console.log('âœ… NPM scripts added\n');
    } catch (error) {
      console.log('âš ï¸  Could not update package.json scripts\n');
    }

    // 6. Create validation script
    console.log('ðŸ§ª Creating load shedding validation script...');
    const validationScript = `#!/usr/bin/env node

/**
 * Load Shedding Validation Script
 */

async function validateLoadShedding() {
  console.log('ðŸ§ª Validating Load Shedding System...\\n');
  
  try {
    // Test load shedding status endpoint
    console.log('ðŸ“Š Testing load shedding status endpoint...');
    const response = await fetch('http://localhost:3000/api/load-shedding/status?metrics=true');
    
    if (response.ok) {
      const data = await response.json();
      console.log('âœ… Load shedding status endpoint working');
      console.log(\`   Status: \${data.status}\`);
      console.log(\`   Shed Level: \${data.loadShedding.admissionControl.shedLevel}\`);
      console.log(\`   Active Throttling: \${data.loadShedding.clientThrottling.summary.activeThrottling}\`);
    } else {
      console.log('âŒ Load shedding status endpoint failed');
    }
    
    // Test admission control
    console.log('\\nðŸšª Testing admission control...');
    const admissionResponse = await fetch('http://localhost:3000/api/health', {
      headers: {
        'X-Priority-Class': 'CRITICAL'
      }
    });
    
    if (admissionResponse.ok) {
      console.log('âœ… Admission control allowing requests');
      const priorityClass = admissionResponse.headers.get('X-Priority-Class');
      const shedLevel = admissionResponse.headers.get('X-Shed-Level');
      console.log(\`   Priority Class: \${priorityClass}\`);
      console.log(\`   Shed Level: \${shedLevel}\`);
    } else {
      console.log('âŒ Admission control test failed');
    }
    
    console.log('\\nðŸŽ‰ Load shedding validation completed!');
    
  } catch (error) {
    console.error('âŒ Load shedding validation failed:', error.message);
    console.log('\\nðŸ’¡ Make sure the development server is running: npm run dev');
  }
}

validateLoadShedding();
`;

    await fs.writeFile('scripts/validate-load-shedding.js', validationScript);
    await fs.chmod('scripts/validate-load-shedding.js', 0o755);
    console.log('âœ… Load shedding validation script created\n');

    // 7. Create documentation
    console.log('ðŸ“š Creating load shedding documentation...');
    const documentation = `# Load Shedding & Overload Management Documentation

## Overview
The load shedding system protects SLOs during overload by intelligently rejecting non-critical requests early, preventing cascade failures and maintaining system stability.

## Components

### 1. Admission Control
Edge-level request filtering based on system resources and load conditions.

**Triggers:**
- CPU usage thresholds (70% warning, 80% shed best-effort, 90% shed important)
- Memory usage thresholds (75% warning, 85% shed best-effort, 92% shed important)
- Latency thresholds (P95 > 1s, P99 > 2s)
- Queue depth limits

**Priority Classes:**
- **Critical**: Authentication, payments, health checks (never shed)
- **Important**: User operations, content creation (shed at high load)
- **Best-effort**: Analytics, reports (shed first)

### 2. Client-side Throttling
Adaptive rate limiting based on server responses and load conditions.

**Features:**
- Exponential backoff on 429/503 responses
- Circuit breaker integration
- Jitter and randomization
- Recovery based on success rate

### 3. Middleware Integration
Next.js middleware for seamless load shedding integration.

**Capabilities:**
- Automatic request classification
- Custom headers for debugging
- Path-based exclusions
- Metrics collection

## Configuration

### Admission Control
\`\`\`json
{
  "admissionControl": {
    "enabled": true,
    "triggers": {
      "cpu": {
        "warning": 70,
        "shedBestEffort": 80,
        "shedImportant": 90,
        "emergency": 95
      }
    }
  }
}
\`\`\`

### Client Throttling
\`\`\`json
{
  "clientThrottling": {
    "api": {
      "enabled": true,
      "baseDelay": 1000,
      "maxDelay": 30000,
      "throttleThreshold": 20
    }
  }
}
\`\`\`

## Usage

### Initialization
\`\`\`typescript
import { initializeLoadShedding } from '@/lib/load-shedding/init';
await initializeLoadShedding();
\`\`\`

### Manual Priority Setting
\`\`\`typescript
// Set request priority
const response = await fetch('/api/endpoint', {
  headers: {
    'X-Priority-Class': 'CRITICAL'
  }
});
\`\`\`

### Client Throttling
\`\`\`typescript
import { executeWithAPIThrottling } from '@/lib/load-shedding/clientThrottling';

const result = await executeWithAPIThrottling(async () => {
  return await fetch('/api/data');
});
\`\`\`

## Load Testing

### Run Load Tests
\`\`\`bash
# Normal load baseline
npm run load-test:normal

# Test 2x load
npm run load-test:2x

# Test 3x load
npm run load-test:3x

# Spike test
npm run load-test:spike
\`\`\`

### Validation
\`\`\`bash
# Validate load shedding system
node scripts/validate-load-shedding.js

# Check system status
npm run load-shedding:status
\`\`\`

## Monitoring

### Key Metrics
- **Shed Level**: Current load shedding level (0-4)
- **Rejection Rate**: % of requests rejected by priority class
- **Throttling Status**: Client-side throttling activity
- **Resource Utilization**: CPU, memory, latency metrics

### API Endpoints
- \`GET /api/load-shedding/status\` - System status and metrics
- \`POST /api/load-shedding/status\` - Configuration updates

### Dashboard
Access the load shedding dashboard at: \`/load-shedding/dashboard\`

## Best Practices

### Priority Classification
1. **Critical**: Never shed, essential for system operation
2. **Important**: Shed only under high load, user-facing operations
3. **Best-effort**: Shed first, background/analytics operations

### Load Testing
1. **Baseline**: Establish normal load patterns
2. **Gradual Increase**: Test 2x, 3x, 5x normal load
3. **Spike Testing**: Sudden load increases
4. **Sustained Load**: Long-duration overload scenarios

### Monitoring
1. **Real-time Alerts**: Set up alerts for shed level changes
2. **SLO Tracking**: Monitor P95/P99 latency during load shedding
3. **Client Behavior**: Track throttling effectiveness
4. **Resource Correlation**: Correlate shedding with resource usage

## Troubleshooting

### Common Issues
1. **Excessive shedding**: Check resource thresholds and system capacity
2. **Client throttling loops**: Verify backoff configuration
3. **Priority misclassification**: Review endpoint priority mapping
4. **Metrics collection**: Ensure monitoring system is functioning

### Debug Commands
\`\`\`bash
# Check load shedding status
curl http://localhost:3000/api/load-shedding/status?metrics=true

# Test specific priority class
curl -H "X-Priority-Class: CRITICAL" http://localhost:3000/api/health

# Run validation
node scripts/validate-load-shedding.js
\`\`\`

## Integration

### With Monitoring (Task 4)
- Load shedding metrics integrate with Golden Signals dashboard
- Overload alerts feed into existing alerting system
- SLO compliance includes load shedding effectiveness

### With Recovery (Task 5)
- Circuit breakers coordinate with admission control
- Auto-healing includes overload recovery
- Graceful degradation works with priority classes

### With Deployments (Task 6)
- Canary deployments monitor load shedding impact
- Error budget includes load shedding in calculations
- Blue-green switches consider current load conditions

## Performance Targets

### Under 2x Load
- P95 latency â‰¤ SLO targets
- Shed rate < 20% for best-effort traffic
- No critical request failures

### Under 3x Load
- P95 latency â‰¤ 1.5x SLO targets
- Shed rate < 50% for non-critical traffic
- System remains stable

### Under 5x Load
- System does not crash
- Critical requests continue to be served
- Graceful degradation maintains core functionality
`;

    await fs.writeFile('docs/LOAD_SHEDDING.md', documentation);
    console.log('âœ… Load shedding documentation created\n');

    // Success message
    console.log('ðŸŽ‰ Load Shedding Setup Complete!\n');
    console.log('ðŸ“‹ Summary:');
    console.log('   âœ… Configuration file created (load-shedding.config.json)');
    console.log('   âœ… Initialization script created (lib/load-shedding/init.ts)');
    console.log('   âœ… Load testing script created (scripts/load-test.js)');
    console.log('   âœ… Validation script created (scripts/validate-load-shedding.js)');
    console.log('   âœ… Documentation created (docs/LOAD_SHEDDING.md)');
    console.log('   âœ… NPM scripts added to package.json\n');
    
    console.log('ðŸš€ Next Steps:');
    console.log('   1. Start your development server: npm run dev');
    console.log('   2. Validate the system: node scripts/validate-load-shedding.js');
    console.log('   3. Run load tests: npm run load-test:normal');
    console.log('   4. Check the documentation: docs/LOAD_SHEDDING.md\n');
    
    console.log('ðŸŽ¯ Load shedding system provides:');
    console.log('   - Admission control with priority-based shedding');
    console.log('   - Client-side adaptive throttling');
    console.log('   - Real-time resource monitoring');
    console.log('   - SLO protection under extreme load');
    console.log('   - Comprehensive load testing capabilities\n');

  } catch (error) {
    console.error('âŒ Load shedding setup failed:', error);
    process.exit(1);
  }
}

// Run setup
setupLoadShedding();